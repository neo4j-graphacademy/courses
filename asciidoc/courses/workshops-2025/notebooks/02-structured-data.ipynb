{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Structured Data Import\n",
    "**Modular GenAI Workshops 2025**\n",
    "\n",
    "This notebook guides you through importing structured data into Neo4j, covering data modeling, CSV import, and optimization techniques.\n",
    "\n",
    "## Learning Objectives\n",
    "- Design effective graph data models\n",
    "- Import structured data using LOAD CSV\n",
    "- Transform and validate data during import\n",
    "- Optimize import performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install neo4j pandas python-dotenv requests"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Install Required Packages\n\nBefore we begin working with structured data import, we need to install essential Python packages:\n\n- **neo4j**: The official Neo4j Python driver for database connectivity\n- **pandas**: For data manipulation and transformation during import\n- **python-dotenv**: For secure environment variable management\n- **requests**: For downloading data from external sources\n\nThese packages provide the foundation for building robust data import pipelines.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Import Libraries and Initialize Environment\n\nHere we import all necessary libraries for our data import workflow:\n\n**Key Libraries:**\n- **datetime**: For handling date/time data transformations\n- **time**: For measuring import performance\n- **random & Faker**: For generating realistic sample data\n- **pandas**: For data manipulation and validation\n\n**Environment Setup:**\nThe `load_dotenv()` function loads our Neo4j credentials from the .env file, keeping sensitive information secure and separate from code.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "\n",
    "load_dotenv()\n",
    "print(\"‚úÖ Packages imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Create Enhanced Neo4j Connection Class\n\nThis `Neo4jImporter` class extends our basic connection with import-specific functionality:\n\n**Key Features:**\n- **`execute()`**: For read queries and schema operations\n- **`execute_write()`**: For write operations with proper transaction handling\n- **Database selection**: Supports connecting to specific Neo4j databases\n- **Error handling**: Robust connection management for long-running imports\n\n**Why This Matters:**\nImport operations require different patterns than simple queries - they need transaction management, better error handling, and performance monitoring.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo4j Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Clear Database and Create Constraints\n\n**Database Preparation:**\nBefore importing new data, we clear any existing data to start fresh. In production, you would be more selective about this!\n\n**Constraints for Data Integrity:**\nWe create UNIQUE constraints on key identifiers:\n- **customer_id**: Ensures no duplicate customers\n- **account_number**: Prevents duplicate accounts\n- **merchant_id**: Maintains merchant uniqueness\n- **location_id**: Ensures location integrity\n\n**Why Constraints Matter:**\n- Prevent data duplication during import\n- Improve query performance \n- Maintain referential integrity\n- Enable safe re-running of import scripts",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Create Performance Indexes\n\n**Index Strategy for Fast Queries:**\n\nWe create indexes on frequently-queried properties:\n- **customer_email & customer_name**: For customer lookups\n- **account_type**: For account categorization queries\n- **merchant_category**: For merchant analysis\n- **transaction_date & transaction_amount**: For transaction analysis\n\n**Index Performance Impact:**\n- Dramatically speeds up WHERE clause filtering\n- Enables efficient sorting and range queries\n- Critical for real-time analytics queries\n- Must be created BEFORE large data imports for best performance",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neo4jImporter:\n",
    "    def __init__(self):\n",
    "        self.uri = os.getenv('NEO4J_URI')\n",
    "        self.username = os.getenv('NEO4J_USERNAME')\n",
    "        self.password = os.getenv('NEO4J_PASSWORD')\n",
    "        self.database = os.getenv('NEO4J_DATABASE', 'neo4j')\n",
    "        self.driver = GraphDatabase.driver(self.uri, auth=(self.username, self.password))\n",
    "    \n",
    "    def execute(self, query, parameters=None):\n",
    "        with self.driver.session(database=self.database) as session:\n",
    "            result = session.run(query, parameters or {})\n",
    "            return [record.data() for record in result]\n",
    "    \n",
    "    def execute_write(self, query, parameters=None):\n",
    "        with self.driver.session(database=self.database) as session:\n",
    "            return session.execute_write(lambda tx: tx.run(query, parameters or {}))\n",
    "    \n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "neo4j = Neo4jImporter()\n",
    "print(\"‚úÖ Neo4j connection established\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Generate Realistic Location Data\n\n**Data Generation Strategy:**\n\nSince we're demonstrating import concepts, we generate realistic sample data using:\n- **Real US cities** with actual coordinates\n- **Faker library** for realistic addresses and postal codes\n- **Geographic distribution** across major metropolitan areas\n\n**Key Learning Points:**\n- Real-world imports often require data transformation\n- Geographic data includes multiple related attributes\n- Data should be realistic for meaningful analysis\n- Small datasets help us understand import patterns before scaling",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Generate Customer Demographic Data\n\n**Customer Data Modeling:**\n\nWe create realistic customer profiles including:\n- **Personal information**: Names, emails, phone numbers\n- **Financial attributes**: Income bracket, credit score\n- **Temporal data**: Registration dates\n- **Geographic references**: Location IDs for relationships\n\n**Data Realism Features:**\n- Age ranges from 18-80 (realistic banking customers)\n- Credit scores follow actual distribution (300-850)\n- Registration dates span 5 years of history\n- Income brackets for financial segmentation",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Generate Merchant Business Data\n\n**Merchant Entity Design:**\n\nCreating diverse merchant data including:\n- **Business information**: Names and establishment years\n- **Categorization**: Primary and subcategories for analytics\n- **Geographic distribution**: Connected to locations\n- **Realistic business types**: Restaurants, retail, gas stations, etc.\n\n**Category Strategy:**\nThe merchant categories are designed to support:\n- Spending pattern analysis\n- Customer behavior insights\n- Fraud detection (unusual category patterns)\n- Recommendation engines",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Generate Account Portfolio Data\n\n**Account Relationship Modeling:**\n\nThis demonstrates a key graph concept: **one-to-many relationships**\n- Each customer can have 1-3 accounts\n- Account types: checking, savings, credit, investment\n- Realistic balance distributions by account type\n- Primary account designation\n\n**Financial Data Realism:**\n- **Checking**: $100-$10,000 (daily spending money)\n- **Savings**: $500-$50,000 (accumulated savings)\n- **Credit**: Negative balances (debt)\n- **Investment**: $1,000-$100,000 (long-term wealth)\n\n**Graph Design Decision:** Accounts are separate entities (not just properties) because they have their own lifecycle and relationships.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Clear Previous Data and Set Up Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Import Location Entities\n\n**Basic Node Creation Pattern:**\n\nThis demonstrates the fundamental import pattern:\n1. **Iterate through data** using pandas DataFrame\n2. **Execute CREATE statements** for each record\n3. **Monitor performance** with timing\n4. **Provide feedback** on import progress\n\n**Learning Points:**\n- Individual CREATE statements are simple but not fastest for large datasets\n- Each row becomes a node with properties\n- Performance timing helps identify bottlenecks\n- Good for understanding the import process before optimization",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Import Merchants with Relationships\n\n**Node + Relationship Creation Pattern:**\n\nThis shows a more complex import pattern:\n1. **Create the merchant node** with business properties\n2. **Create relationship to location** using MATCH + CREATE\n3. **Handle foreign key references** through location_id\n\n**Key Graph Concepts:**\n- **Two-step process**: Create node, then connect to existing nodes\n- **MATCH before CREATE**: Find existing location to connect to\n- **Foreign key mapping**: location_id becomes a graph relationship\n- **Relationship semantics**: LOCATED_IN expresses business-location connection",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Import Customers with Data Validation\n\n**Data Validation During Import:**\n\nThis demonstrates production-quality import practices:\n1. **Validate data quality** before creating nodes\n2. **Skip invalid records** with helpful counters\n3. **Add computed properties** (risk_category based on credit_score)\n4. **Create relationships** to geographic data\n\n**Validation Rules:**\n- Email must contain '@' symbol\n- Age must be realistic (18-120)\n- Skip bad data rather than failing entire import\n\n**Computed Properties:** \nRisk categories are calculated during import, creating analytics-ready data from the start.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Import Account Portfolio with Business Logic\n\n**Advanced Import with Business Rules:**\n\nThis pattern shows sophisticated import logic:\n1. **Business validation**: Skip accounts with negative balances (except credit)\n2. **Computed categorization**: Balance categories for analytics\n3. **Relationship properties**: HAS_ACCOUNT has opening date and primary flag\n4. **Single transaction**: Create account and relationship together\n\n**Graph Design Excellence:**\n- **Rich relationships**: The HAS_ACCOUNT relationship carries meaningful data\n- **Analytics preparation**: Balance categories enable fast segmentation\n- **Data consistency**: Business rules prevent invalid data states",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear existing data (be careful with this in production!)\n",
    "print(\"üßπ Clearing existing data...\")\n",
    "neo4j.execute(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "# Create constraints for data integrity\n",
    "print(\"üîß Creating constraints...\")\n",
    "constraints = [\n",
    "    \"CREATE CONSTRAINT customer_id IF NOT EXISTS FOR (c:Customer) REQUIRE c.id IS UNIQUE\",\n",
    "    \"CREATE CONSTRAINT account_number IF NOT EXISTS FOR (a:Account) REQUIRE a.number IS UNIQUE\",\n",
    "    \"CREATE CONSTRAINT merchant_id IF NOT EXISTS FOR (m:Merchant) REQUIRE m.id IS UNIQUE\",\n",
    "    \"CREATE CONSTRAINT location_id IF NOT EXISTS FOR (l:Location) REQUIRE l.id IS UNIQUE\"\n",
    "]\n",
    "\n",
    "for constraint in constraints:\n",
    "    try:\n",
    "        neo4j.execute(constraint)\n",
    "        print(f\"‚úÖ {constraint.split()[2]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  {constraint.split()[2]}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Generate Transaction Activity Data\n\n**Transaction Data Complexity:**\n\nFinancial transactions represent the most complex data in our graph:\n- **Account-to-account relationships**: Money flow between entities\n- **Temporal patterns**: Date/time stamps for activity analysis\n- **Amount variations**: Realistic distributions by transaction type\n- **Channel tracking**: How transactions occur (online, mobile, ATM)\n- **Merchant connections**: Purchase transactions link to merchants\n\n**Business Logic in Data Generation:**\n- Different amount ranges by transaction type\n- Temporal patterns (recent transactions)\n- Channel diversity for analysis\n- Merchant integration for purchase tracking",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Import Complex Transaction Relationships\n\n**Multi-Relationship Import Pattern:**\n\nThis demonstrates the most sophisticated import pattern:\n1. **Account-to-account TRANSACTION** relationships with rich properties\n2. **Conditional merchant relationships** for purchase transactions\n3. **Multiple computed properties** for analytics\n4. **Complex validation** (positive amounts, different accounts)\n\n**Analytics-Ready Properties:**\n- **amount_category**: Enables fast transaction size analysis\n- **is_weekend**: Supports fraud detection patterns\n- **hour_of_day**: Time-based behavior analysis\n- **PURCHASED_FROM**: Direct merchant-customer connection tracking\n\n**Performance Note:** This creates the most relationships and is typically the slowest import step.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indexes for performance\n",
    "print(\"üìä Creating indexes...\")\n",
    "indexes = [\n",
    "    \"CREATE INDEX customer_email IF NOT EXISTS FOR (c:Customer) ON (c.email)\",\n",
    "    \"CREATE INDEX customer_name IF NOT EXISTS FOR (c:Customer) ON (c.name)\",\n",
    "    \"CREATE INDEX account_type IF NOT EXISTS FOR (a:Account) ON (a.type)\",\n",
    "    \"CREATE INDEX merchant_category IF NOT EXISTS FOR (m:Merchant) ON (m.category)\",\n",
    "    \"CREATE INDEX transaction_date IF NOT EXISTS FOR ()-[t:TRANSACTION]-() ON (t.date)\",\n",
    "    \"CREATE INDEX transaction_amount IF NOT EXISTS FOR ()-[t:TRANSACTION]-() ON (t.amount)\"\n",
    "]\n",
    "\n",
    "for index in indexes:\n",
    "    try:\n",
    "        neo4j.execute(index)\n",
    "        print(f\"‚úÖ {index.split()[2]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  {index.split()[2]}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Comprehensive Data Quality Validation\n\n**Post-Import Data Verification:**\n\nAfter importing data, always validate the results:\n1. **Completeness checks**: Count nodes and relationships\n2. **Orphaned data detection**: Find nodes without expected relationships\n3. **Data distribution analysis**: Verify realistic patterns\n4. **Referential integrity**: Ensure all relationships are valid\n\n**Why Validation Matters:**\n- Catches import errors early\n- Verifies data distribution is realistic\n- Identifies performance issues\n- Provides confidence in data quality for analytics",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate Sample Data\n",
    "Since we're working with sample data, let's create some realistic financial data."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Query Performance Analysis\n\n**Testing Import Success with Performance Metrics:**\n\nAfter import, test that your indexes and data structure support efficient queries:\n1. **Index effectiveness**: Email searches should be sub-second\n2. **Relationship traversals**: Complex queries across multiple hops\n3. **Aggregate operations**: Count/sum operations on large datasets\n\n**Performance Benchmarking:**\n- Sub-second response times indicate good index usage\n- Multiple second response times suggest missing indexes\n- Compare performance before/after index creation\n- Monitor query patterns that will be used in production",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "# Install faker if not available\n",
    "try:\n",
    "    fake = Faker()\n",
    "except:\n",
    "    !pip install faker\n",
    "    fake = Faker()\n",
    "\n",
    "# Generate sample locations data\n",
    "locations_data = []\n",
    "cities = [\n",
    "    ('New York', 'NY', 'USA', 40.7128, -74.0060),\n",
    "    ('Los Angeles', 'CA', 'USA', 34.0522, -118.2437),\n",
    "    ('Chicago', 'IL', 'USA', 41.8781, -87.6298),\n",
    "    ('Houston', 'TX', 'USA', 29.7604, -95.3698),\n",
    "    ('Phoenix', 'AZ', 'USA', 33.4484, -112.0740),\n",
    "    ('Philadelphia', 'PA', 'USA', 39.9526, -75.1652),\n",
    "    ('San Antonio', 'TX', 'USA', 29.4241, -98.4936),\n",
    "    ('San Diego', 'CA', 'USA', 32.7157, -117.1611),\n",
    "    ('Dallas', 'TX', 'USA', 32.7767, -96.7970),\n",
    "    ('San Jose', 'CA', 'USA', 37.3382, -121.8863)\n",
    "]\n",
    "\n",
    "for i, (city, state, country, lat, lon) in enumerate(cities, 1):\n",
    "    locations_data.append({\n",
    "        'location_id': i,\n",
    "        'city': city,\n",
    "        'state': state,\n",
    "        'country': country,\n",
    "        'zip_code': fake.zipcode(),\n",
    "        'latitude': lat,\n",
    "        'longitude': lon\n",
    "    })\n",
    "\n",
    "df_locations = pd.DataFrame(locations_data)\n",
    "print(f\"Generated {len(df_locations)} locations\")\n",
    "df_locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Customer Similarity Analysis for AI Applications\n\n**Graph-Based Recommendation Engine Pattern:**\n\nThis query demonstrates how graph structures enable advanced analytics:\n1. **Multi-hop traversal**: Customer ‚Üí Account ‚Üí Purchase ‚Üí Merchant ‚Üê Purchase ‚Üê Account ‚Üê Customer\n2. **Pattern recognition**: Find customers with shared purchasing behavior\n3. **Similarity scoring**: Count shared merchants as similarity metric\n4. **AI application**: Foundation for collaborative filtering recommendations\n\n**Business Value:**\nThis pattern enables personalized recommendations: \"Customers like you also shop at...\"",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Fraud Detection Pattern Analysis\n\n**Anomaly Detection Using Graph Patterns:**\n\nThis query shows how to identify potentially fraudulent activity:\n1. **Behavioral patterns**: Large transactions on weekends (unusual timing)\n2. **Risk correlation**: Connect transaction patterns to customer risk profiles\n3. **Context enrichment**: Include transaction details for investigation\n4. **Prioritization**: Order by amount to focus on highest-risk activities\n\n**Fraud Detection Insights:**\n- Weekend large transactions may indicate compromised accounts\n- Risk category correlation helps prioritize investigations\n- Graph queries naturally combine multiple risk factors",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Geographic Wealth Distribution Analysis\n\n**Spatial Analytics with Graph Data:**\n\nThis query demonstrates geographic analysis capabilities:\n1. **Geographic aggregation**: Group customers by location\n2. **Wealth concentration**: Sum account balances by region\n3. **Customer density**: Count customers per location\n4. **Market insights**: Identify high-value geographic markets\n\n**Business Applications:**\n- Branch location planning\n- Marketing campaign targeting\n- Risk assessment by geography\n- Market penetration analysis\n\n**Graph Advantage:** Easily traverse customer ‚Üí location relationships for spatial analytics.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample customers data\n",
    "customers_data = []\n",
    "for i in range(1, 101):  # 100 customers\n",
    "    customers_data.append({\n",
    "        'customer_id': i,\n",
    "        'full_name': fake.name(),\n",
    "        'email': fake.email(),\n",
    "        'phone': fake.phone_number(),\n",
    "        'age': random.randint(18, 80),\n",
    "        'income_bracket': random.choice(['Low', 'Medium', 'High', 'Very High']),\n",
    "        'credit_score': random.randint(300, 850),\n",
    "        'registration_date': fake.date_between(start_date='-5y', end_date='today'),\n",
    "        'location_id': random.randint(1, len(locations_data))\n",
    "    })\n",
    "\n",
    "df_customers = pd.DataFrame(customers_data)\n",
    "print(f\"Generated {len(df_customers)} customers\")\n",
    "df_customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample merchants data\n",
    "merchant_categories = ['Restaurant', 'Retail', 'Gas Station', 'Grocery', 'Online', 'ATM', 'Pharmacy', 'Entertainment']\n",
    "merchants_data = []\n",
    "\n",
    "for i in range(1, 51):  # 50 merchants\n",
    "    category = random.choice(merchant_categories)\n",
    "    merchants_data.append({\n",
    "        'merchant_id': i,\n",
    "        'merchant_name': fake.company(),\n",
    "        'category': category,\n",
    "        'subcategory': f\"{category} - {fake.word().title()}\",\n",
    "        'established_year': random.randint(1980, 2020),\n",
    "        'location_id': random.randint(1, len(locations_data))\n",
    "    })\n",
    "\n",
    "df_merchants = pd.DataFrame(merchants_data)\n",
    "print(f\"Generated {len(df_merchants)} merchants\")\n",
    "df_merchants.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Graceful Resource Cleanup\n\n**Proper Connection Management:**\n\nAlways close database connections properly:\n- Releases connection pool resources\n- Prevents connection leaks\n- Ensures clean shutdown\n- Good practice for production applications\n\nThis is especially important in Jupyter notebooks where connections can persist between cell executions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample accounts data\n",
    "account_types = ['checking', 'savings', 'credit', 'investment']\n",
    "accounts_data = []\n",
    "account_counter = 1\n",
    "\n",
    "for customer_id in range(1, 101):\n",
    "    # Each customer has 1-3 accounts\n",
    "    num_accounts = random.randint(1, 3)\n",
    "    \n",
    "    for _ in range(num_accounts):\n",
    "        account_type = random.choice(account_types)\n",
    "        \n",
    "        # Balance varies by account type\n",
    "        if account_type == 'checking':\n",
    "            balance = random.uniform(100, 10000)\n",
    "        elif account_type == 'savings':\n",
    "            balance = random.uniform(500, 50000)\n",
    "        elif account_type == 'credit':\n",
    "            balance = -random.uniform(0, 5000)  # Credit accounts have negative balances\n",
    "        else:  # investment\n",
    "            balance = random.uniform(1000, 100000)\n",
    "        \n",
    "        accounts_data.append({\n",
    "            'customer_id': customer_id,\n",
    "            'account_number': f\"ACC{account_counter:06d}\",\n",
    "            'account_type': account_type,\n",
    "            'current_balance': round(balance, 2),\n",
    "            'opened_date': fake.date_between(start_date='-3y', end_date='today'),\n",
    "            'status': random.choice(['active', 'active', 'active', 'closed']),  # 75% active\n",
    "            'is_primary': 'true' if _ == 0 else 'false'  # First account is primary\n",
    "        })\n",
    "        account_counter += 1\n",
    "\n",
    "df_accounts = pd.DataFrame(accounts_data)\n",
    "print(f\"Generated {len(df_accounts)} accounts\")\n",
    "df_accounts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Import Data Using LOAD CSV Pattern\n",
    "We'll simulate the LOAD CSV process by importing our generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Locations\n",
    "print(\"üìç Importing locations...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for _, row in df_locations.iterrows():\n",
    "    neo4j.execute(\"\"\"\n",
    "        CREATE (l:Location {\n",
    "            id: $location_id,\n",
    "            city: $city,\n",
    "            state: $state,\n",
    "            country: $country,\n",
    "            zip_code: $zip_code,\n",
    "            latitude: $latitude,\n",
    "            longitude: $longitude\n",
    "        })\n",
    "    \"\"\", row.to_dict())\n",
    "\n",
    "print(f\"‚úÖ Imported {len(df_locations)} locations in {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Merchants\n",
    "print(\"üè™ Importing merchants...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for _, row in df_merchants.iterrows():\n",
    "    # Create merchant\n",
    "    neo4j.execute(\"\"\"\n",
    "        CREATE (m:Merchant {\n",
    "            id: $merchant_id,\n",
    "            name: $merchant_name,\n",
    "            category: $category,\n",
    "            subcategory: $subcategory,\n",
    "            established_year: $established_year\n",
    "        })\n",
    "    \"\"\", row.to_dict())\n",
    "    \n",
    "    # Connect to location\n",
    "    neo4j.execute(\"\"\"\n",
    "        MATCH (m:Merchant {id: $merchant_id})\n",
    "        MATCH (l:Location {id: $location_id})\n",
    "        CREATE (m)-[:LOCATED_IN]->(l)\n",
    "    \"\"\", row.to_dict())\n",
    "\n",
    "print(f\"‚úÖ Imported {len(df_merchants)} merchants in {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Customers with data validation\n",
    "print(\"üë• Importing customers...\")\n",
    "start_time = time.time()\n",
    "imported_count = 0\n",
    "skipped_count = 0\n",
    "\n",
    "for _, row in df_customers.iterrows():\n",
    "    # Data validation\n",
    "    if '@' not in row['email'] or row['age'] < 18 or row['age'] > 120:\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "    \n",
    "    # Create customer with computed risk category\n",
    "    risk_category = 'low' if row['credit_score'] >= 750 else 'medium' if row['credit_score'] >= 650 else 'high'\n",
    "    \n",
    "    customer_data = row.to_dict()\n",
    "    customer_data['risk_category'] = risk_category\n",
    "    \n",
    "    neo4j.execute(\"\"\"\n",
    "        CREATE (c:Customer {\n",
    "            id: $customer_id,\n",
    "            name: $full_name,\n",
    "            email: $email,\n",
    "            phone: $phone,\n",
    "            age: $age,\n",
    "            income_bracket: $income_bracket,\n",
    "            credit_score: $credit_score,\n",
    "            registration_date: date($registration_date),\n",
    "            risk_category: $risk_category\n",
    "        })\n",
    "    \"\"\", customer_data)\n",
    "    \n",
    "    # Connect to location\n",
    "    neo4j.execute(\"\"\"\n",
    "        MATCH (c:Customer {id: $customer_id})\n",
    "        MATCH (l:Location {id: $location_id})\n",
    "        CREATE (c)-[:LIVES_IN]->(l)\n",
    "    \"\"\", customer_data)\n",
    "    \n",
    "    imported_count += 1\n",
    "\n",
    "print(f\"‚úÖ Imported {imported_count} customers, skipped {skipped_count} in {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Accounts\n",
    "print(\"üè¶ Importing accounts...\")\n",
    "start_time = time.time()\n",
    "imported_count = 0\n",
    "\n",
    "for _, row in df_accounts.iterrows():\n",
    "    # Only import accounts for valid customers and positive balances for non-credit accounts\n",
    "    if row['account_type'] != 'credit' and row['current_balance'] < 0:\n",
    "        continue\n",
    "    \n",
    "    # Create account with computed properties\n",
    "    balance = row['current_balance']\n",
    "    if balance < 1000:\n",
    "        balance_category = 'low'\n",
    "    elif balance < 10000:\n",
    "        balance_category = 'medium'\n",
    "    elif balance < 100000:\n",
    "        balance_category = 'high'\n",
    "    else:\n",
    "        balance_category = 'very_high'\n",
    "    \n",
    "    account_data = row.to_dict()\n",
    "    account_data['balance_category'] = balance_category\n",
    "    \n",
    "    neo4j.execute(\"\"\"\n",
    "        MATCH (c:Customer {id: $customer_id})\n",
    "        CREATE (a:Account {\n",
    "            number: $account_number,\n",
    "            type: $account_type,\n",
    "            balance: $current_balance,\n",
    "            opened_date: date($opened_date),\n",
    "            status: $status,\n",
    "            balance_category: $balance_category\n",
    "        })\n",
    "        CREATE (c)-[:HAS_ACCOUNT {\n",
    "            opened: date($opened_date),\n",
    "            primary_account: $is_primary = 'true'\n",
    "        }]->(a)\n",
    "    \"\"\", account_data)\n",
    "    \n",
    "    imported_count += 1\n",
    "\n",
    "print(f\"‚úÖ Imported {imported_count} accounts in {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate and Import Transaction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample transactions\n",
    "print(\"üí≥ Generating transaction data...\")\n",
    "\n",
    "# Get all account numbers\n",
    "accounts = neo4j.execute(\"\"\"\n",
    "    MATCH (a:Account) \n",
    "    RETURN a.number AS number, a.type AS type\n",
    "\"\"\")\n",
    "\n",
    "account_numbers = [acc['number'] for acc in accounts]\n",
    "transaction_types = ['transfer', 'payment', 'deposit', 'withdrawal', 'purchase']\n",
    "channels = ['online', 'mobile', 'atm', 'branch', 'phone']\n",
    "\n",
    "transactions_data = []\n",
    "for i in range(1, 1001):  # Generate 1000 transactions\n",
    "    from_account = random.choice(account_numbers)\n",
    "    to_account = random.choice([acc for acc in account_numbers if acc != from_account])\n",
    "    \n",
    "    transaction_type = random.choice(transaction_types)\n",
    "    \n",
    "    # Amount varies by transaction type\n",
    "    if transaction_type == 'purchase':\n",
    "        amount = round(random.uniform(5, 500), 2)\n",
    "    elif transaction_type == 'transfer':\n",
    "        amount = round(random.uniform(50, 5000), 2)\n",
    "    else:\n",
    "        amount = round(random.uniform(20, 2000), 2)\n",
    "    \n",
    "    transactions_data.append({\n",
    "        'transaction_id': f\"TXN{i:06d}\",\n",
    "        'from_account': from_account,\n",
    "        'to_account': to_account,\n",
    "        'amount': amount,\n",
    "        'transaction_timestamp': fake.date_time_between(start_date='-1y', end_date='now'),\n",
    "        'transaction_type': transaction_type,\n",
    "        'description': f\"{transaction_type.title()} - {fake.sentence(nb_words=3)}\",\n",
    "        'channel': random.choice(channels),\n",
    "        'merchant_id': random.choice(range(1, 26)) if transaction_type == 'purchase' else None\n",
    "    })\n",
    "\n",
    "df_transactions = pd.DataFrame(transactions_data)\n",
    "print(f\"Generated {len(df_transactions)} transactions\")\n",
    "df_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Transactions\n",
    "print(\"üí∏ Importing transactions...\")\n",
    "start_time = time.time()\n",
    "imported_count = 0\n",
    "\n",
    "for _, row in df_transactions.iterrows():\n",
    "    # Validate transaction data\n",
    "    if row['amount'] <= 0 or row['from_account'] == row['to_account']:\n",
    "        continue\n",
    "    \n",
    "    # Compute additional properties\n",
    "    amount = row['amount']\n",
    "    if amount < 50:\n",
    "        amount_category = 'micro'\n",
    "    elif amount < 500:\n",
    "        amount_category = 'small'\n",
    "    elif amount < 5000:\n",
    "        amount_category = 'medium'\n",
    "    else:\n",
    "        amount_category = 'large'\n",
    "    \n",
    "    transaction_data = row.to_dict()\n",
    "    transaction_data['amount_category'] = amount_category\n",
    "    transaction_data['is_weekend'] = row['transaction_timestamp'].weekday() >= 5\n",
    "    transaction_data['hour_of_day'] = row['transaction_timestamp'].hour\n",
    "    \n",
    "    # Create transaction relationship\n",
    "    neo4j.execute(\"\"\"\n",
    "        MATCH (from:Account {number: $from_account})\n",
    "        MATCH (to:Account {number: $to_account})\n",
    "        CREATE (from)-[:TRANSACTION {\n",
    "            id: $transaction_id,\n",
    "            amount: $amount,\n",
    "            date: datetime($transaction_timestamp),\n",
    "            type: $transaction_type,\n",
    "            description: $description,\n",
    "            channel: $channel,\n",
    "            amount_category: $amount_category,\n",
    "            is_weekend: $is_weekend,\n",
    "            hour_of_day: $hour_of_day\n",
    "        }]->(to)\n",
    "    \"\"\", transaction_data)\n",
    "    \n",
    "    # Connect to merchant if applicable\n",
    "    if row['merchant_id'] is not None:\n",
    "        neo4j.execute(\"\"\"\n",
    "            MATCH (from:Account {number: $from_account})-[t:TRANSACTION {id: $transaction_id}]->(to:Account)\n",
    "            MATCH (m:Merchant {id: $merchant_id})\n",
    "            CREATE (from)-[:PURCHASED_FROM {transaction_id: $transaction_id, amount: $amount}]->(m)\n",
    "        \"\"\", transaction_data)\n",
    "    \n",
    "    imported_count += 1\n",
    "\n",
    "print(f\"‚úÖ Imported {imported_count} transactions in {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Data Quality Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive data validation\n",
    "print(\"üîç Validating imported data...\")\n",
    "\n",
    "# Check data completeness\n",
    "data_stats = neo4j.execute(\"\"\"\n",
    "    MATCH (c:Customer)\n",
    "    OPTIONAL MATCH (c)-[:HAS_ACCOUNT]->(a:Account)\n",
    "    OPTIONAL MATCH (a)-[t:TRANSACTION]-()\n",
    "    RETURN 'Data Coverage' AS metric,\n",
    "           count(DISTINCT c) AS customers,\n",
    "           count(DISTINCT a) AS accounts,\n",
    "           count(t) AS transactions\n",
    "\"\"\")\n",
    "\n",
    "for stat in data_stats:\n",
    "    print(f\"üìä {stat['metric']}: {stat['customers']} customers, {stat['accounts']} accounts, {stat['transactions']} transactions\")\n",
    "\n",
    "# Check for orphaned data\n",
    "orphaned_accounts = neo4j.execute(\"\"\"\n",
    "    MATCH (a:Account)\n",
    "    WHERE NOT (a)<-[:HAS_ACCOUNT]-()\n",
    "    RETURN count(a) AS orphaned_accounts\n",
    "\"\"\")\n",
    "\n",
    "print(f\"üîó Orphaned accounts: {orphaned_accounts[0]['orphaned_accounts']}\")\n",
    "\n",
    "# Check data distribution\n",
    "risk_distribution = neo4j.execute(\"\"\"\n",
    "    MATCH (c:Customer)\n",
    "    RETURN c.risk_category AS risk_level,\n",
    "           count(c) AS customer_count,\n",
    "           avg(c.credit_score) AS avg_credit_score\n",
    "    ORDER BY risk_level\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüìà Customer Risk Distribution:\")\n",
    "for dist in risk_distribution:\n",
    "    print(f\"  {dist['risk_level']}: {dist['customer_count']} customers (avg credit: {dist['avg_credit_score']:.0f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query performance\n",
    "print(\"‚ö° Testing query performance...\")\n",
    "\n",
    "# Test 1: Customer lookup by email (should be fast with index)\n",
    "start_time = time.time()\n",
    "result = neo4j.execute(\"\"\"\n",
    "    MATCH (c:Customer) \n",
    "    WHERE c.email CONTAINS '@gmail.com'\n",
    "    RETURN count(c) AS gmail_customers\n",
    "\"\"\")\n",
    "print(f\"üìß Email search: {time.time() - start_time:.3f}s - Found {result[0]['gmail_customers']} Gmail users\")\n",
    "\n",
    "# Test 2: Transaction pattern analysis\n",
    "start_time = time.time()\n",
    "result = neo4j.execute(\"\"\"\n",
    "    MATCH ()-[t:TRANSACTION]-()\n",
    "    WHERE t.amount > 1000\n",
    "    RETURN count(t) AS large_transactions\n",
    "\"\"\")\n",
    "print(f\"üí∞ Large transaction search: {time.time() - start_time:.3f}s - Found {result[0]['large_transactions']} large transactions\")\n",
    "\n",
    "# Test 3: Complex relationship query\n",
    "start_time = time.time()\n",
    "result = neo4j.execute(\"\"\"\n",
    "    MATCH (c:Customer)-[:HAS_ACCOUNT]->(a:Account)-[:TRANSACTION]->()\n",
    "    WITH c, count(*) AS transaction_count\n",
    "    WHERE transaction_count > 5\n",
    "    RETURN count(c) AS active_customers\n",
    "\"\"\")\n",
    "print(f\"üîÑ Complex relationship query: {time.time() - start_time:.3f}s - Found {result[0]['active_customers']} active customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: AI-Ready Data Analysis\n",
    "Let's test some queries that would be useful for AI applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer similarity analysis for recommendations\n",
    "print(\"ü§ñ AI Application Testing...\")\n",
    "\n",
    "customer_similarity = neo4j.execute(\"\"\"\n",
    "    MATCH (c1:Customer)-[:HAS_ACCOUNT]->()-[:PURCHASED_FROM]->(m:Merchant)\n",
    "          <-[:PURCHASED_FROM]-()-[:HAS_ACCOUNT]-(c2:Customer)\n",
    "    WHERE c1 <> c2\n",
    "    WITH c1, c2, count(DISTINCT m) AS shared_merchants\n",
    "    WHERE shared_merchants >= 2\n",
    "    RETURN c1.name AS customer1, c2.name AS customer2, shared_merchants,\n",
    "           c1.risk_category AS risk1, c2.risk_category AS risk2\n",
    "    ORDER BY shared_merchants DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüéØ Customer Similarity (for recommendations):\")\n",
    "for sim in customer_similarity:\n",
    "    print(f\"  {sim['customer1']} ‚Üî {sim['customer2']}: {sim['shared_merchants']} shared merchants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud detection patterns\n",
    "fraud_patterns = neo4j.execute(\"\"\"\n",
    "    MATCH (a:Account)-[t:TRANSACTION]->()\n",
    "    WHERE t.amount > 2000 AND t.is_weekend = true\n",
    "    MATCH (a)<-[:HAS_ACCOUNT]-(c:Customer)\n",
    "    RETURN c.name AS customer, c.risk_category, t.amount, t.date, t.description\n",
    "    ORDER BY t.amount DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüö® Potential Fraud Patterns (Large weekend transactions):\")\n",
    "for pattern in fraud_patterns:\n",
    "    print(f\"  {pattern['customer']} ({pattern['risk_category']}): ${pattern['amount']:.2f} on {pattern['date']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic analysis\n",
    "geographic_analysis = neo4j.execute(\"\"\"\n",
    "    MATCH (c:Customer)-[:LIVES_IN]->(l:Location)\n",
    "    MATCH (c)-[:HAS_ACCOUNT]->(a:Account)\n",
    "    WITH l, count(c) AS customer_count, sum(a.balance) AS total_deposits\n",
    "    WHERE customer_count > 2\n",
    "    RETURN l.city AS city, l.state AS state, customer_count, total_deposits\n",
    "    ORDER BY total_deposits DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüó∫Ô∏è Geographic Analysis (Customer concentration and wealth):\")\n",
    "for geo in geographic_analysis:\n",
    "    print(f\"  {geo['city']}, {geo['state']}: {geo['customer_count']} customers, ${geo['total_deposits']:,.2f} total deposits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Learnings\n",
    "\n",
    "In this module, you successfully:\n",
    "\n",
    "### ‚úÖ **Data Modeling**\n",
    "- Designed a graph model from relational concepts\n",
    "- Made strategic decisions about nodes vs. properties\n",
    "- Considered performance implications in the design\n",
    "\n",
    "### ‚úÖ **Import Process**\n",
    "- Set up proper constraints and indexes before import\n",
    "- Implemented data validation during import\n",
    "- Added computed properties for analytics\n",
    "- Handled relationships and foreign key mappings\n",
    "\n",
    "### ‚úÖ **Performance Optimization**\n",
    "- Created appropriate indexes for query patterns\n",
    "- Used constraints for data integrity\n",
    "- Validated import performance\n",
    "\n",
    "### ‚úÖ **AI Readiness**\n",
    "- Created graph structures suitable for ML feature engineering\n",
    "- Implemented patterns for recommendation systems\n",
    "- Designed fraud detection query patterns\n",
    "- Enabled geographic and demographic analysis\n",
    "\n",
    "### üéØ **Best Practices Learned**\n",
    "1. **Always validate data** during import\n",
    "2. **Create indexes before** large imports\n",
    "3. **Design for your query patterns**, not just data structure\n",
    "4. **Add computed properties** to support analytics\n",
    "5. **Test performance** with realistic data volumes\n",
    "\n",
    "### üöÄ **Next Steps**\n",
    "In the next module, we'll learn how to work with unstructured data and create knowledge graphs from text documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close Neo4j connection\n",
    "neo4j.close()\n",
    "print(\"‚úÖ Neo4j connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}