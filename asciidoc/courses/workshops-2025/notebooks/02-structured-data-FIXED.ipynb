{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Structured Data Modeling and Import\n",
    "\n",
    "Welcome to Module 2! Now that you understand graph fundamentals, let's dive into the practical world of data modeling and importing real datasets into Neo4j. This is where your graph applications start to come alive with meaningful data.\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "\n",
    "By the end of this module, you'll be able to:\n",
    "- Design effective graph data models for complex business scenarios\n",
    "- Import CSV and structured data efficiently into Neo4j\n",
    "- Apply data modeling best practices and design patterns\n",
    "- Handle data quality issues and validation\n",
    "- Optimize import performance for large datasets\n",
    "- Create indexes and constraints for data integrity\n",
    "\n",
    "## üß† Why This Matters\n",
    "\n",
    "Most real-world graph applications start with existing data in spreadsheets, databases, or APIs. Learning to effectively model and import this data is crucial because:\n",
    "\n",
    "**Poor data modeling** leads to:\n",
    "- Complex, slow queries\n",
    "- Difficult maintenance\n",
    "- Limited scalability\n",
    "\n",
    "**Good data modeling** enables:\n",
    "- Intuitive, fast queries\n",
    "- Easy application development\n",
    "- Excellent performance at scale\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Prerequisites\n",
    "\n",
    "- Completion of Module 1: Graph Basics\n",
    "- Understanding of basic Cypher queries\n",
    "- Familiarity with CSV data and spreadsheets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Lesson 1: Data Modeling Fundamentals (15 minutes)\n",
    "\n",
    "## ü§î Think About This Real-World Scenario\n",
    "\n",
    "Imagine you're building a movie recommendation system like Netflix. You have spreadsheets with:\n",
    "- Movies (titles, genres, release dates, budgets)\n",
    "- People (actors, directors, writers)\n",
    "- User ratings and reviews\n",
    "- Box office data\n",
    "\n",
    "**Question**: How do you transform this tabular data into a graph that can power intelligent recommendations?\n",
    "\n",
    "This is the challenge of **data modeling** - designing a graph structure that represents your domain effectively.\n",
    "\n",
    "## üèóÔ∏è The Data Modeling Process\n",
    "\n",
    "Graph data modeling follows a proven process:\n",
    "\n",
    "### 1. **Understand the Domain**\n",
    "- What questions will users ask?\n",
    "- What are the key entities and how do they relate?\n",
    "- What business rules apply?\n",
    "\n",
    "### 2. **Identify the Entities** (Nodes)\n",
    "- **Nouns** in your domain ‚Üí Nodes\n",
    "- Examples: Movie, Person, Genre, User\n",
    "\n",
    "### 3. **Identify the Relationships**\n",
    "- **Verbs** describing connections ‚Üí Relationships\n",
    "- Examples: ACTED_IN, DIRECTED, RATED, SIMILAR_TO\n",
    "\n",
    "### 4. **Add Properties**\n",
    "- **Attributes** of entities and relationships ‚Üí Properties\n",
    "- Examples: title, name, rating, timestamp\n",
    "\n",
    "### 5. **Validate with Queries**\n",
    "- Can you answer the key business questions?\n",
    "- Are the queries intuitive and performant?\n",
    "\n",
    "## üí° Data Modeling Principles\n",
    "\n",
    "### ‚úÖ Good Practices:\n",
    "- **Model for your queries**: Design around the questions you need to answer\n",
    "- **Use meaningful names**: `ACTED_IN` not `REL_TYPE_1`\n",
    "- **Represent relationships explicitly**: Don't hide connections in properties\n",
    "- **Favor specific relationships**: `DIRECTED` vs generic `ASSOCIATED_WITH`\n",
    "\n",
    "### ‚ùå Common Mistakes:\n",
    "- **Modeling like SQL**: Thinking in tables instead of connections\n",
    "- **Over-normalization**: Creating unnecessary intermediate nodes\n",
    "- **Under-normalization**: Storing everything as properties\n",
    "- **Generic relationships**: Losing semantic meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Let's Start With Setup\n",
    "\n",
    "First, let's set up our environment for this module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries for data processing and Neo4j\n",
    "!pip install neo4j pandas numpy requests faker\n",
    "\n",
    "print(\"‚úÖ Libraries installed! Ready for data modeling and import.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our toolkit for data modeling\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, date\n",
    "import requests\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Set up faker for generating realistic data\n",
    "fake = Faker()\n",
    "random.seed(42)  # For reproducible examples\n",
    "\n",
    "print(\"üìö Data modeling toolkit ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j connection setup\n",
    "NEO4J_URI = os.getenv('NEO4J_URI', 'bolt://localhost:7687')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME', 'neo4j')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD', 'password')\n",
    "\n",
    "# Create our connection\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "def run_query(query, parameters=None):\n",
    "    \"\"\"\n",
    "    Execute a Cypher query and return results.\n",
    "    This helper function makes it easy to run queries throughout the module.\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query, parameters or {})\n",
    "        return [record.data() for record in result]\n",
    "\n",
    "# Test connection\n",
    "test_result = run_query(\"RETURN 'Ready for data modeling!' as message\")\n",
    "print(f\"üéâ {test_result[0]['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé¨ Our Domain: Movie Recommendation System\n",
    "\n",
    "Let's model a movie recommendation system similar to what Netflix or IMDb might use. This domain is rich with relationships and perfect for demonstrating graph modeling principles.\n",
    "\n",
    "### Key Questions Our Model Should Answer:\n",
    "1. \"What movies did Tom Hanks star in?\"\n",
    "2. \"Who directed Inception?\"\n",
    "3. \"What genres does this user prefer?\"\n",
    "4. \"Which movies are similar to ones I've rated highly?\"\n",
    "5. \"What movies should I recommend to this user?\"\n",
    "\n",
    "### Domain Analysis:\n",
    "\n",
    "**Entities (Nodes):**\n",
    "- `Movie` - Films in our database\n",
    "- `Person` - Actors, directors, writers\n",
    "- `Genre` - Categories like Action, Drama, Comedy\n",
    "- `User` - People who rate and review movies\n",
    "\n",
    "**Relationships:**\n",
    "- `ACTED_IN` - Person ‚Üí Movie\n",
    "- `DIRECTED` - Person ‚Üí Movie  \n",
    "- `WROTE` - Person ‚Üí Movie\n",
    "- `IN_GENRE` - Movie ‚Üí Genre\n",
    "- `RATED` - User ‚Üí Movie\n",
    "- `SIMILAR_TO` - Movie ‚Üí Movie\n",
    "\n",
    "Let's start by clearing our workspace and building this model step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the database for our movie modeling exercise\n",
    "run_query(\"MATCH (n) DETACH DELETE n\")\n",
    "print(\"üßπ Database cleared - ready to build our movie recommendation graph!\")\n",
    "\n",
    "# Let's also check that we have a clean start\n",
    "node_count = run_query(\"MATCH (n) RETURN count(n) as count\")[0]['count']\n",
    "print(f\"Current node count: {node_count} (should be 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create Our Schema - Constraints and Indexes\n",
    "\n",
    "Before importing data, it's a best practice to set up constraints and indexes. This ensures data quality and query performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create uniqueness constraints to prevent duplicate data\n",
    "# These also automatically create indexes for performance\n",
    "\n",
    "constraints = [\n",
    "    \"CREATE CONSTRAINT movie_id IF NOT EXISTS FOR (m:Movie) REQUIRE m.id IS UNIQUE\",\n",
    "    \"CREATE CONSTRAINT person_id IF NOT EXISTS FOR (p:Person) REQUIRE p.id IS UNIQUE\", \n",
    "    \"CREATE CONSTRAINT genre_name IF NOT EXISTS FOR (g:Genre) REQUIRE g.name IS UNIQUE\",\n",
    "    \"CREATE CONSTRAINT user_id IF NOT EXISTS FOR (u:User) REQUIRE u.id IS UNIQUE\"\n",
    "]\n",
    "\n",
    "print(\"üîí Creating constraints for data integrity...\")\n",
    "for constraint in constraints:\n",
    "    try:\n",
    "        run_query(constraint)\n",
    "        print(f\"   ‚úÖ {constraint.split()[2]} constraint created\")\n",
    "    except Exception as e:\n",
    "        if \"already exists\" in str(e):\n",
    "            print(f\"   ‚ö†Ô∏è {constraint.split()[2]} constraint already exists\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Error creating constraint: {e}\")\n",
    "\n",
    "print(\"\\nüöÄ Schema setup complete! Our data will be clean and performant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Knowledge Check #1\n",
    "\n",
    "Before we continue, let's make sure you understand the modeling decisions:\n",
    "\n",
    "**Question**: Why did we create separate `Person` and `Movie` nodes instead of storing actor names as properties on movies?\n",
    "\n",
    "**Think about it, then check below:**\n",
    "\n",
    "<details>\n",
    "<summary>Click to see the answer</summary>\n",
    "\n",
    "**Separate nodes are better because:**\n",
    "\n",
    "1. **Reusability**: Tom Hanks appears in many movies - we store his info once, not repeatedly\n",
    "2. **Relationships**: We can query \"all movies Tom Hanks starred in\" naturally\n",
    "3. **Rich data**: People have their own properties (birthdate, nationality, etc.)\n",
    "4. **Query power**: \"Find actors who worked together\" becomes a simple graph traversal\n",
    "5. **Data integrity**: Changes to person info update everywhere automatically\n",
    "\n",
    "This is the power of **thinking in graphs** vs. thinking in tables!\n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2: Creating Sample Data (15 minutes)\n",
    "\n",
    "## üìä Generating Realistic Movie Data\n",
    "\n",
    "To understand data modeling and import patterns, let's create realistic sample data. In real projects, this data would come from APIs, databases, or CSV files.\n",
    "\n",
    "### Creating Our Dataset\n",
    "\n",
    "We'll generate data that mimics what you'd find in real movie databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic movie data\n",
    "def create_movie_dataset():\n",
    "    \"\"\"Generate a realistic movie dataset for our modeling exercise\"\"\"\n",
    "    \n",
    "    print(\"üé¨ Generating movie dataset...\")\n",
    "    \n",
    "    # Define genres\n",
    "    genres = [\n",
    "        'Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary',\n",
    "        'Drama', 'Family', 'Fantasy', 'Horror', 'Mystery', 'Romance', \n",
    "        'Science Fiction', 'Thriller', 'War', 'Western'\n",
    "    ]\n",
    "    \n",
    "    # Generate people (actors, directors, writers)\n",
    "    people = []\n",
    "    for i in range(50):\n",
    "        person = {\n",
    "            'id': f'person_{i:03d}',\n",
    "            'name': fake.name(),\n",
    "            'born': fake.date_between(start_date='-80y', end_date='-20y'),\n",
    "            'nationality': fake.country(),\n",
    "            'roles': random.sample(['actor', 'director', 'writer'], k=random.randint(1, 2))\n",
    "        }\n",
    "        people.append(person)\n",
    "    \n",
    "    # Generate movies\n",
    "    movies = []\n",
    "    for i in range(30):\n",
    "        # Create realistic movie titles\n",
    "        title_patterns = [\n",
    "            f\"The {fake.word().title()}\",\n",
    "            f\"{fake.word().title()} {fake.word().title()}\",\n",
    "            f\"{fake.first_name()}'s {fake.word().title()}\",\n",
    "            f\"The {fake.word().title()} of {fake.word().title()}\"\n",
    "        ]\n",
    "        \n",
    "        movie = {\n",
    "            'id': f'movie_{i:03d}',\n",
    "            'title': random.choice(title_patterns),\n",
    "            'released': fake.date_between(start_date='-30y', end_date='today'),\n",
    "            'runtime': random.randint(90, 180),\n",
    "            'budget': random.randint(1000000, 200000000),\n",
    "            'revenue': random.randint(500000, 500000000),\n",
    "            'plot': fake.text(max_nb_chars=200),\n",
    "            'genres': random.sample(genres, k=random.randint(1, 3))\n",
    "        }\n",
    "        movies.append(movie)\n",
    "    \n",
    "    # Generate users\n",
    "    users = []\n",
    "    for i in range(20):\n",
    "        user = {\n",
    "            'id': f'user_{i:03d}',\n",
    "            'username': fake.user_name(),\n",
    "            'email': fake.email(),\n",
    "            'joined': fake.date_between(start_date='-5y', end_date='today'),\n",
    "            'age': random.randint(18, 70)\n",
    "        }\n",
    "        users.append(user)\n",
    "    \n",
    "    return {\n",
    "        'people': people,\n",
    "        'movies': movies,\n",
    "        'genres': [{'name': genre} for genre in genres],\n",
    "        'users': users\n",
    "    }\n",
    "\n",
    "# Generate our dataset\n",
    "dataset = create_movie_dataset()\n",
    "\n",
    "print(f\"üìä Dataset created:\")\n",
    "print(f\"   - {len(dataset['people'])} people\")\n",
    "print(f\"   - {len(dataset['movies'])} movies\")\n",
    "print(f\"   - {len(dataset['genres'])} genres\")\n",
    "print(f\"   - {len(dataset['users'])} users\")\n",
    "\n",
    "# Show sample data\n",
    "print(f\"\\nüé¨ Sample movie: {dataset['movies'][0]['title']}\")\n",
    "print(f\"   Released: {dataset['movies'][0]['released']}\")\n",
    "print(f\"   Genres: {', '.join(dataset['movies'][0]['genres'])}\")\n",
    "print(f\"   Plot: {dataset['movies'][0]['plot'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Our Data Structure\n",
    "\n",
    "Before importing, let's examine what we have. This step is crucial in real projects - you need to understand your data before modeling it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore our data structure\n",
    "print(\"üîç Exploring our dataset structure...\\n\")\n",
    "\n",
    "# Convert to pandas for easy analysis\n",
    "movies_df = pd.DataFrame(dataset['movies'])\n",
    "people_df = pd.DataFrame(dataset['people'])\n",
    "users_df = pd.DataFrame(dataset['users'])\n",
    "\n",
    "print(\"üìΩÔ∏è Movies DataFrame info:\")\n",
    "print(f\"   Shape: {movies_df.shape}\")\n",
    "print(f\"   Columns: {list(movies_df.columns)}\")\n",
    "print(f\"   Date range: {movies_df['released'].min()} to {movies_df['released'].max()}\")\n",
    "print(f\"   Budget range: ${movies_df['budget'].min():,} to ${movies_df['budget'].max():,}\")\n",
    "\n",
    "print(\"\\nüë• People DataFrame info:\")\n",
    "print(f\"   Shape: {people_df.shape}\")\n",
    "print(f\"   Columns: {list(people_df.columns)}\")\n",
    "\n",
    "# Show role distribution\n",
    "all_roles = []\n",
    "for person in dataset['people']:\n",
    "    all_roles.extend(person['roles'])\n",
    "role_counts = pd.Series(all_roles).value_counts()\n",
    "print(f\"   Role distribution: {dict(role_counts)}\")\n",
    "\n",
    "print(\"\\nüë§ Users DataFrame info:\")\n",
    "print(f\"   Shape: {users_df.shape}\")\n",
    "print(f\"   Age range: {users_df['age'].min()} to {users_df['age'].max()}\")\n",
    "\n",
    "# Display sample records\n",
    "print(\"\\nüìä Sample records:\")\n",
    "print(\"\\nSample Movie:\")\n",
    "print(json.dumps(dataset['movies'][0], indent=2, default=str))\n",
    "\n",
    "print(\"\\nSample Person:\")\n",
    "print(json.dumps(dataset['people'][0], indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Save Data for Import Practice\n",
    "\n",
    "In real projects, you often receive data as CSV files. Let's save our data in CSV format to practice import techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our datasets as CSV files for import practice\n",
    "import os\n",
    "\n",
    "# Create data directory\n",
    "data_dir = 'movie_data'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "print(\"üíæ Saving datasets as CSV files...\")\n",
    "\n",
    "# Save movies (need to handle list columns)\n",
    "movies_for_csv = []\n",
    "for movie in dataset['movies']:\n",
    "    movie_copy = movie.copy()\n",
    "    movie_copy['genres'] = '|'.join(movie['genres'])  # Convert list to pipe-separated string\n",
    "    movies_for_csv.append(movie_copy)\n",
    "\n",
    "movies_df = pd.DataFrame(movies_for_csv)\n",
    "movies_df.to_csv(f'{data_dir}/movies.csv', index=False)\n",
    "print(f\"   ‚úÖ movies.csv ({len(movies_df)} records)\")\n",
    "\n",
    "# Save people (handle roles list)\n",
    "people_for_csv = []\n",
    "for person in dataset['people']:\n",
    "    person_copy = person.copy()\n",
    "    person_copy['roles'] = '|'.join(person['roles'])\n",
    "    people_for_csv.append(person_copy)\n",
    "\n",
    "people_df = pd.DataFrame(people_for_csv)\n",
    "people_df.to_csv(f'{data_dir}/people.csv', index=False)\n",
    "print(f\"   ‚úÖ people.csv ({len(people_df)} records)\")\n",
    "\n",
    "# Save genres\n",
    "genres_df = pd.DataFrame(dataset['genres'])\n",
    "genres_df.to_csv(f'{data_dir}/genres.csv', index=False)\n",
    "print(f\"   ‚úÖ genres.csv ({len(genres_df)} records)\")\n",
    "\n",
    "# Save users\n",
    "users_df = pd.DataFrame(dataset['users'])\n",
    "users_df.to_csv(f'{data_dir}/users.csv', index=False)\n",
    "print(f\"   ‚úÖ users.csv ({len(users_df)} records)\")\n",
    "\n",
    "print(f\"\\nüìÅ All CSV files saved to '{data_dir}/' directory\")\n",
    "\n",
    "# Show what our CSV looks like\n",
    "print(\"\\nüëÄ Sample CSV content (movies.csv):\")\n",
    "print(movies_df.head(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Knowledge Check #2\n",
    "\n",
    "**Question**: Why did we convert the `genres` list to a pipe-separated string when saving to CSV?\n",
    "\n",
    "**Think about it, then check below:**\n",
    "\n",
    "<details>\n",
    "<summary>Click to see the answer</summary>\n",
    "\n",
    "**CSV limitations require this transformation:**\n",
    "\n",
    "1. **CSV format**: CSV files can't natively store arrays/lists - each cell contains one value\n",
    "2. **Common pattern**: Pipe-separated (or comma-separated) strings are a standard way to represent multiple values in CSV\n",
    "3. **Import flexibility**: When importing, we can easily split the string back into individual genre relationships\n",
    "4. **Readability**: Humans can still read \"Action|Adventure|Drama\" in the CSV file\n",
    "\n",
    "This is a common data engineering pattern you'll use frequently when working with real datasets!\n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3: Data Import Strategies (20 minutes)\n",
    "\n",
    "## üöÄ The Art of Data Import\n",
    "\n",
    "Now for the exciting part - bringing our data to life in Neo4j! There are several strategies for importing data, each with its own advantages.\n",
    "\n",
    "### Import Strategy Options:\n",
    "\n",
    "1. **CREATE statements** - Good for small datasets, learning\n",
    "2. **LOAD CSV** - Built-in, handles medium datasets well\n",
    "3. **APOC procedures** - Advanced features, large datasets\n",
    "4. **Bulk import tool** - Massive datasets, initial loads\n",
    "5. **Application code** - Custom logic, real-time imports\n",
    "\n",
    "We'll focus on the first two since they cover most use cases.\n",
    "\n",
    "## Method 1: Direct CREATE Statements\n",
    "\n",
    "Let's start by importing our data using direct CREATE statements. This approach gives you full control and is perfect for understanding the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Import using direct CREATE statements\n",
    "print(\"üèóÔ∏è Importing data using CREATE statements...\\n\")\n",
    "\n",
    "# Step 1: Import Genres (they have no dependencies)\n",
    "print(\"1Ô∏è‚É£ Creating genres...\")\n",
    "for genre in dataset['genres']:\n",
    "    run_query(\"\"\"\n",
    "    CREATE (g:Genre {name: $name})\n",
    "    \"\"\", {'name': genre['name']})\n",
    "\n",
    "genre_count = run_query(\"MATCH (g:Genre) RETURN count(g) as count\")[0]['count']\n",
    "print(f\"   ‚úÖ Created {genre_count} genres\")\n",
    "\n",
    "# Step 2: Import People\n",
    "print(\"\\n2Ô∏è‚É£ Creating people...\")\n",
    "for person in dataset['people']:\n",
    "    run_query(\"\"\"\n",
    "    CREATE (p:Person {\n",
    "        id: $id,\n",
    "        name: $name,\n",
    "        born: date($born),\n",
    "        nationality: $nationality\n",
    "    })\n",
    "    \"\"\", {\n",
    "        'id': person['id'],\n",
    "        'name': person['name'],\n",
    "        'born': person['born'].isoformat(),\n",
    "        'nationality': person['nationality']\n",
    "    })\n",
    "\n",
    "people_count = run_query(\"MATCH (p:Person) RETURN count(p) as count\")[0]['count']\n",
    "print(f\"   ‚úÖ Created {people_count} people\")\n",
    "\n",
    "# Step 3: Import Users\n",
    "print(\"\\n3Ô∏è‚É£ Creating users...\")\n",
    "for user in dataset['users']:\n",
    "    run_query(\"\"\"\n",
    "    CREATE (u:User {\n",
    "        id: $id,\n",
    "        username: $username,\n",
    "        email: $email,\n",
    "        joined: date($joined),\n",
    "        age: $age\n",
    "    })\n",
    "    \"\"\", {\n",
    "        'id': user['id'],\n",
    "        'username': user['username'],\n",
    "        'email': user['email'],\n",
    "        'joined': user['joined'].isoformat(),\n",
    "        'age': user['age']\n",
    "    })\n",
    "\n",
    "user_count = run_query(\"MATCH (u:User) RETURN count(u) as count\")[0]['count']\n",
    "print(f\"   ‚úÖ Created {user_count} users\")\n",
    "\n",
    "# Step 4: Import Movies and create genre relationships\n",
    "print(\"\\n4Ô∏è‚É£ Creating movies and connecting to genres...\")\n",
    "for movie in dataset['movies']:\n",
    "    # Create the movie\n",
    "    run_query(\"\"\"\n",
    "    CREATE (m:Movie {\n",
    "        id: $id,\n",
    "        title: $title,\n",
    "        released: date($released),\n",
    "        runtime: $runtime,\n",
    "        budget: $budget,\n",
    "        revenue: $revenue,\n",
    "        plot: $plot\n",
    "    })\n",
    "    \"\"\", {\n",
    "        'id': movie['id'],\n",
    "        'title': movie['title'],\n",
    "        'released': movie['released'].isoformat(),\n",
    "        'runtime': movie['runtime'],\n",
    "        'budget': movie['budget'],\n",
    "        'revenue': movie['revenue'],\n",
    "        'plot': movie['plot']\n",
    "    })\n",
    "    \n",
    "    # Connect to genres\n",
    "    for genre_name in movie['genres']:\n",
    "        run_query(\"\"\"\n",
    "        MATCH (m:Movie {id: $movie_id}),\n",
    "              (g:Genre {name: $genre_name})\n",
    "        CREATE (m)-[:IN_GENRE]->(g)\n",
    "        \"\"\", {\n",
    "            'movie_id': movie['id'],\n",
    "            'genre_name': genre_name\n",
    "        })\n",
    "\n",
    "movie_count = run_query(\"MATCH (m:Movie) RETURN count(m) as count\")[0]['count']\n",
    "genre_rel_count = run_query(\"MATCH ()-[r:IN_GENRE]->() RETURN count(r) as count\")[0]['count']\n",
    "print(f\"   ‚úÖ Created {movie_count} movies\")\n",
    "print(f\"   ‚úÖ Created {genre_rel_count} genre relationships\")\n",
    "\n",
    "print(\"\\nüéâ Data import complete using CREATE statements!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Movie Industry Relationships\n",
    "\n",
    "Now let's add the relationships that make our graph interesting - who acted in what, who directed what, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic movie industry relationships\n",
    "print(\"üé¨ Creating movie industry relationships...\\n\")\n",
    "\n",
    "# Get our data for creating relationships\n",
    "movies = run_query(\"MATCH (m:Movie) RETURN m.id as id\")\n",
    "people = run_query(\"MATCH (p:Person) RETURN p.id as id\")\n",
    "\n",
    "# Create ACTED_IN relationships\n",
    "print(\"1Ô∏è‚É£ Creating ACTED_IN relationships...\")\n",
    "acted_count = 0\n",
    "for movie in movies:\n",
    "    # Each movie has 3-6 actors\n",
    "    num_actors = random.randint(3, 6)\n",
    "    selected_actors = random.sample(people, num_actors)\n",
    "    \n",
    "    for actor in selected_actors:\n",
    "        # Create relationship with role property\n",
    "        role = fake.first_name() if random.random() > 0.7 else None  # Some have character names\n",
    "        run_query(\"\"\"\n",
    "        MATCH (p:Person {id: $person_id}),\n",
    "              (m:Movie {id: $movie_id})\n",
    "        CREATE (p)-[:ACTED_IN {role: $role}]->(m)\n",
    "        \"\"\", {\n",
    "            'person_id': actor['id'],\n",
    "            'movie_id': movie['id'],\n",
    "            'role': role\n",
    "        })\n",
    "        acted_count += 1\n",
    "\n",
    "print(f\"   ‚úÖ Created {acted_count} ACTED_IN relationships\")\n",
    "\n",
    "# Create DIRECTED relationships\n",
    "print(\"\\n2Ô∏è‚É£ Creating DIRECTED relationships...\")\n",
    "directed_count = 0\n",
    "for movie in movies:\n",
    "    # Each movie has 1-2 directors\n",
    "    num_directors = random.randint(1, 2)\n",
    "    selected_directors = random.sample(people, num_directors)\n",
    "    \n",
    "    for director in selected_directors:\n",
    "        run_query(\"\"\"\n",
    "        MATCH (p:Person {id: $person_id}),\n",
    "              (m:Movie {id: $movie_id})\n",
    "        CREATE (p)-[:DIRECTED]->(m)\n",
    "        \"\"\", {\n",
    "            'person_id': director['id'],\n",
    "            'movie_id': movie['id']\n",
    "        })\n",
    "        directed_count += 1\n",
    "\n",
    "print(f\"   ‚úÖ Created {directed_count} DIRECTED relationships\")\n",
    "\n",
    "# Create WROTE relationships\n",
    "print(\"\\n3Ô∏è‚É£ Creating WROTE relationships...\")\n",
    "wrote_count = 0\n",
    "for movie in movies:\n",
    "    # Each movie has 1-3 writers\n",
    "    num_writers = random.randint(1, 3)\n",
    "    selected_writers = random.sample(people, num_writers)\n",
    "    \n",
    "    for writer in selected_writers:\n",
    "        run_query(\"\"\"\n",
    "        MATCH (p:Person {id: $person_id}),\n",
    "              (m:Movie {id: $movie_id})\n",
    "        CREATE (p)-[:WROTE]->(m)\n",
    "        \"\"\", {\n",
    "            'person_id': writer['id'],\n",
    "            'movie_id': movie['id']\n",
    "        })\n",
    "        wrote_count += 1\n",
    "\n",
    "print(f\"   ‚úÖ Created {wrote_count} WROTE relationships\")\n",
    "\n",
    "print(\"\\nüé≠ Movie industry relationships created!\")\n",
    "print(f\"Total relationships: {acted_count + directed_count + wrote_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add User Ratings\n",
    "\n",
    "Finally, let's add user ratings to make our recommendation system complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user ratings\n",
    "print(\"‚≠ê Creating user ratings...\\n\")\n",
    "\n",
    "users = run_query(\"MATCH (u:User) RETURN u.id as id\")\n",
    "movies = run_query(\"MATCH (m:Movie) RETURN m.id as id\")\n",
    "\n",
    "rating_count = 0\n",
    "for user in users:\n",
    "    # Each user rates 5-15 movies\n",
    "    num_ratings = random.randint(5, 15)\n",
    "    selected_movies = random.sample(movies, num_ratings)\n",
    "    \n",
    "    for movie in selected_movies:\n",
    "        # Generate realistic ratings (skewed toward positive)\n",
    "        rating = random.choices(\n",
    "            [1, 2, 3, 4, 5],\n",
    "            weights=[5, 10, 20, 35, 30]  # More positive ratings\n",
    "        )[0]\n",
    "        \n",
    "        # Create rating relationship\n",
    "        run_query(\"\"\"\n",
    "        MATCH (u:User {id: $user_id}),\n",
    "              (m:Movie {id: $movie_id})\n",
    "        CREATE (u)-[:RATED {\n",
    "            rating: $rating,\n",
    "            timestamp: datetime($timestamp)\n",
    "        }]->(m)\n",
    "        \"\"\", {\n",
    "            'user_id': user['id'],\n",
    "            'movie_id': movie['id'],\n",
    "            'rating': rating,\n",
    "            'timestamp': fake.date_time_between(start_date='-2y', end_date='now').isoformat()\n",
    "        })\n",
    "        rating_count += 1\n",
    "\n",
    "print(f\"   ‚úÖ Created {rating_count} user ratings\")\n",
    "\n",
    "# Let's see the rating distribution\n",
    "rating_dist = run_query(\"\"\"\n",
    "MATCH ()-[r:RATED]->()\n",
    "RETURN r.rating as rating, count(*) as count\n",
    "ORDER BY rating\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüìä Rating distribution:\")\n",
    "for dist in rating_dist:\n",
    "    stars = '‚≠ê' * int(dist['rating'])\n",
    "    print(f\"   {stars} ({dist['rating']}): {dist['count']} ratings\")\n",
    "\n",
    "print(\"\\nüéâ Complete movie recommendation graph created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Verify Our Import\n",
    "\n",
    "Let's verify that our import worked correctly and explore what we've created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive verification of our imported data\n",
    "print(\"üîç Verifying our movie recommendation graph...\\n\")\n",
    "\n",
    "# Node counts\n",
    "node_counts = run_query(\"\"\"\n",
    "MATCH (n)\n",
    "RETURN labels(n)[0] as label, count(n) as count\n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"üìä Node counts:\")\n",
    "total_nodes = 0\n",
    "for count_info in node_counts:\n",
    "    print(f\"   {count_info['label']}: {count_info['count']:,}\")\n",
    "    total_nodes += count_info['count']\n",
    "print(f\"   TOTAL: {total_nodes:,} nodes\")\n",
    "\n",
    "# Relationship counts\n",
    "rel_counts = run_query(\"\"\"\n",
    "MATCH ()-[r]-()\n",
    "RETURN type(r) as relationship_type, count(r) as count\n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüîó Relationship counts:\")\n",
    "total_rels = 0\n",
    "for rel_info in rel_counts:\n",
    "    print(f\"   {rel_info['relationship_type']}: {rel_info['count']:,}\")\n",
    "    total_rels += rel_info['count']\n",
    "print(f\"   TOTAL: {total_rels:,} relationships\")\n",
    "\n",
    "# Sample queries to verify data quality\n",
    "print(\"\\n‚úÖ Data quality checks:\")\n",
    "\n",
    "# Check 1: Movies with genres\n",
    "movies_with_genres = run_query(\"\"\"\n",
    "MATCH (m:Movie)-[:IN_GENRE]->(g:Genre)\n",
    "RETURN count(DISTINCT m) as movies_with_genres\n",
    "\"\"\")[0]['movies_with_genres']\n",
    "total_movies = run_query(\"MATCH (m:Movie) RETURN count(m) as count\")[0]['count']\n",
    "print(f\"   Movies with genres: {movies_with_genres}/{total_movies} ({movies_with_genres/total_movies:.1%})\")\n",
    "\n",
    "# Check 2: Movies with cast\n",
    "movies_with_cast = run_query(\"\"\"\n",
    "MATCH (m:Movie)<-[:ACTED_IN]-(p:Person)\n",
    "RETURN count(DISTINCT m) as movies_with_cast\n",
    "\"\"\")[0]['movies_with_cast']\n",
    "print(f\"   Movies with cast: {movies_with_cast}/{total_movies} ({movies_with_cast/total_movies:.1%})\")\n",
    "\n",
    "# Check 3: Users with ratings\n",
    "users_with_ratings = run_query(\"\"\"\n",
    "MATCH (u:User)-[:RATED]->(m:Movie)\n",
    "RETURN count(DISTINCT u) as users_with_ratings\n",
    "\"\"\")[0]['users_with_ratings']\n",
    "total_users = run_query(\"MATCH (u:User) RETURN count(u) as count\")[0]['count']\n",
    "print(f\"   Users with ratings: {users_with_ratings}/{total_users} ({users_with_ratings/total_users:.1%})\")\n",
    "\n",
    "print(\"\\nüéâ Graph verification complete - data looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Test Our Model with Business Queries\n",
    "\n",
    "The true test of a good data model is whether it can answer business questions elegantly. Let's try the questions we identified earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our data model with real business queries\n",
    "print(\"üéØ Testing our model with business questions...\\n\")\n",
    "\n",
    "# Question 1: \"What movies did [person] star in?\"\n",
    "sample_actor = run_query(\"MATCH (p:Person)-[:ACTED_IN]->() RETURN p.name as name LIMIT 1\")[0]['name']\n",
    "actor_movies = run_query(\"\"\"\n",
    "MATCH (p:Person {name: $name})-[:ACTED_IN]->(m:Movie)\n",
    "RETURN m.title as title, m.released as released\n",
    "ORDER BY m.released DESC\n",
    "\"\"\", {'name': sample_actor})\n",
    "\n",
    "print(f\"1Ô∏è‚É£ Movies starring {sample_actor}:\")\n",
    "for movie in actor_movies[:3]:\n",
    "    print(f\"   - {movie['title']} ({movie['released'].year})\")\n",
    "\n",
    "# Question 2: \"Who directed [movie]?\"\n",
    "sample_movie = run_query(\"MATCH (m:Movie)<-[:DIRECTED]-() RETURN m.title as title LIMIT 1\")[0]['title']\n",
    "directors = run_query(\"\"\"\n",
    "MATCH (p:Person)-[:DIRECTED]->(m:Movie {title: $title})\n",
    "RETURN p.name as director\n",
    "\"\"\", {'title': sample_movie})\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£ Directors of '{sample_movie}':\")\n",
    "for director in directors:\n",
    "    print(f\"   - {director['director']}\")\n",
    "\n",
    "# Question 3: \"What genres does this user prefer?\"\n",
    "sample_user = run_query(\"MATCH (u:User)-[:RATED]->() RETURN u.username as username LIMIT 1\")[0]['username']\n",
    "user_genres = run_query(\"\"\"\n",
    "MATCH (u:User {username: $username})-[r:RATED]->(m:Movie)-[:IN_GENRE]->(g:Genre)\n",
    "WHERE r.rating >= 4\n",
    "RETURN g.name as genre, count(*) as high_rated_count\n",
    "ORDER BY high_rated_count DESC\n",
    "LIMIT 3\n",
    "\"\"\", {'username': sample_user})\n",
    "\n",
    "print(f\"\\n3Ô∏è‚É£ Preferred genres for user '{sample_user}' (4+ star ratings):\")\n",
    "for genre in user_genres:\n",
    "    print(f\"   - {genre['genre']}: {genre['high_rated_count']} movies\")\n",
    "\n",
    "# Question 4: \"Which movies are similar to ones I've rated highly?\"\n",
    "similar_movies = run_query(\"\"\"\n",
    "MATCH (u:User {username: $username})-[r:RATED]->(liked:Movie)\n",
    "WHERE r.rating >= 4\n",
    "MATCH (liked)-[:IN_GENRE]->(g:Genre)<-[:IN_GENRE]-(similar:Movie)\n",
    "WHERE NOT (u)-[:RATED]->(similar)\n",
    "WITH similar, count(g) as shared_genres\n",
    "RETURN similar.title as title, shared_genres\n",
    "ORDER BY shared_genres DESC\n",
    "LIMIT 3\n",
    "\"\"\", {'username': sample_user})\n",
    "\n",
    "print(f\"\\n4Ô∏è‚É£ Movies similar to ones {sample_user} liked:\")\n",
    "for movie in similar_movies:\n",
    "    print(f\"   - {movie['title']} ({movie['shared_genres']} shared genres)\")\n",
    "\n",
    "# Question 5: \"What movies should I recommend to this user?\"\n",
    "recommendations = run_query(\"\"\"\n",
    "MATCH (target:User {username: $username})-[r1:RATED]->(m:Movie)<-[r2:RATED]-(other:User)\n",
    "WHERE r1.rating >= 4 AND r2.rating >= 4 AND target <> other\n",
    "MATCH (other)-[r3:RATED]->(rec:Movie)\n",
    "WHERE r3.rating >= 4 AND NOT (target)-[:RATED]->(rec)\n",
    "RETURN rec.title as recommended_movie, \n",
    "       count(*) as recommendation_strength,\n",
    "       avg(r3.rating) as avg_rating\n",
    "ORDER BY recommendation_strength DESC, avg_rating DESC\n",
    "LIMIT 3\n",
    "\"\"\", {'username': sample_user})\n",
    "\n",
    "print(f\"\\n5Ô∏è‚É£ Recommendations for {sample_user} (collaborative filtering):\")\n",
    "for rec in recommendations:\n",
    "    print(f\"   - {rec['recommended_movie']} (strength: {rec['recommendation_strength']}, avg rating: {rec['avg_rating']:.1f})\")\n",
    "\n",
    "print(\"\\n‚úÖ All business questions answered successfully!\")\n",
    "print(\"üéâ Our data model is working perfectly for movie recommendations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Knowledge Check #3\n",
    "\n",
    "**Question**: Looking at our recommendation query (#5), explain why it works and what pattern it's using.\n",
    "\n",
    "**Think about it, then check below:**\n",
    "\n",
    "<details>\n",
    "<summary>Click to see the answer</summary>\n",
    "\n",
    "**This is collaborative filtering in action:**\n",
    "\n",
    "1. **Find similar users**: Users who rated the same movies highly as the target user\n",
    "2. **Discover their preferences**: What other movies did these similar users rate highly?\n",
    "3. **Filter unrated**: Only recommend movies the target user hasn't seen\n",
    "4. **Rank by strength**: Movies recommended by multiple similar users rank higher\n",
    "\n",
    "**The graph pattern**: `(target)-[:RATED]->(movie)<-[:RATED]-(similar)-[:RATED]->(recommendation)`\n",
    "\n",
    "This is incredibly natural in a graph but would require complex JOINs in SQL. The graph structure makes collaborative filtering almost trivial to implement!\n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4: Advanced Import Techniques (15 minutes)\n",
    "\n",
    "## üöÄ Method 2: LOAD CSV - The Production Approach\n",
    "\n",
    "While CREATE statements are great for learning, `LOAD CSV` is the go-to method for production imports. It's built into Neo4j and handles larger datasets efficiently.\n",
    "\n",
    "Let's clear our database and reimport using LOAD CSV to see the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear database for LOAD CSV demonstration\n",
    "print(\"üßπ Clearing database for LOAD CSV demonstration...\")\n",
    "run_query(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "# Recreate constraints (they were deleted with the data)\n",
    "constraints = [\n",
    "    \"CREATE CONSTRAINT movie_id IF NOT EXISTS FOR (m:Movie) REQUIRE m.id IS UNIQUE\",\n",
    "    \"CREATE CONSTRAINT person_id IF NOT EXISTS FOR (p:Person) REQUIRE p.id IS UNIQUE\", \n",
    "    \"CREATE CONSTRAINT genre_name IF NOT EXISTS FOR (g:Genre) REQUIRE g.name IS UNIQUE\",\n",
    "    \"CREATE CONSTRAINT user_id IF NOT EXISTS FOR (u:User) REQUIRE u.id IS UNIQUE\"\n",
    "]\n",
    "\n",
    "for constraint in constraints:\n",
    "    try:\n",
    "        run_query(constraint)\n",
    "    except:\n",
    "        pass  # Constraint might already exist\n",
    "\n",
    "print(\"‚úÖ Database cleared and constraints recreated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding LOAD CSV\n",
    "\n",
    "`LOAD CSV` is powerful because it:\n",
    "- Handles large files efficiently\n",
    "- Supports data transformation during import\n",
    "- Provides built-in error handling\n",
    "- Works with local files and URLs\n",
    "\n",
    "**Basic syntax**:\n",
    "```cypher\n",
    "LOAD CSV WITH HEADERS FROM 'file:///path/to/file.csv' AS row\n",
    "CREATE (n:Label {property: row.column_name})\n",
    "```\n",
    "\n",
    "Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Import using LOAD CSV\n",
    "print(\"üìÇ Importing data using LOAD CSV...\\n\")\n",
    "\n",
    "# First, we need to get the absolute path to our CSV files\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "data_path = os.path.join(current_dir, 'movie_data')\n",
    "\n",
    "print(f\"üìÅ CSV files location: {data_path}\")\n",
    "\n",
    "# For this demo, we'll load the CSV content and pass it as parameters\n",
    "# In production, you'd use actual LOAD CSV with file URLs\n",
    "\n",
    "# Load and import genres\n",
    "print(\"\\n1Ô∏è‚É£ Importing genres from CSV...\")\n",
    "genres_df = pd.read_csv(f'{data_path}/genres.csv')\n",
    "\n",
    "# Batch import genres (more efficient than one-by-one)\n",
    "genre_data = genres_df.to_dict('records')\n",
    "run_query(\"\"\"\n",
    "UNWIND $genres as genre\n",
    "CREATE (g:Genre {name: genre.name})\n",
    "\"\"\", {'genres': genre_data})\n",
    "\n",
    "genre_count = run_query(\"MATCH (g:Genre) RETURN count(g) as count\")[0]['count']\n",
    "print(f\"   ‚úÖ Imported {genre_count} genres\")\n",
    "\n",
    "# Load and import people\n",
    "print(\"\\n2Ô∏è‚É£ Importing people from CSV...\")\n",
    "people_df = pd.read_csv(f'{data_path}/people.csv')\n",
    "\n",
    "# Convert date strings and prepare data\n",
    "people_data = []\n",
    "for _, person in people_df.iterrows():\n",
    "    people_data.append({\n",
    "        'id': person['id'],\n",
    "        'name': person['name'],\n",
    "        'born': person['born'],\n",
    "        'nationality': person['nationality'],\n",
    "        'roles': person['roles'].split('|')  # Convert back to list\n",
    "    })\n",
    "\n",
    "run_query(\"\"\"\n",
    "UNWIND $people as person\n",
    "CREATE (p:Person {\n",
    "    id: person.id,\n",
    "    name: person.name,\n",
    "    born: date(person.born),\n",
    "    nationality: person.nationality\n",
    "})\n",
    "\"\"\", {'people': people_data})\n",
    "\n",
    "people_count = run_query(\"MATCH (p:Person) RETURN count(p) as count\")[0]['count']\n",
    "print(f\"   ‚úÖ Imported {people_count} people\")\n",
    "\n",
    "# Load and import users\n",
    "print(\"\\n3Ô∏è‚É£ Importing users from CSV...\")\n",
    "users_df = pd.read_csv(f'{data_path}/users.csv')\n",
    "user_data = users_df.to_dict('records')\n",
    "\n",
    "run_query(\"\"\"\n",
    "UNWIND $users as user\n",
    "CREATE (u:User {\n",
    "    id: user.id,\n",
    "    username: user.username,\n",
    "    email: user.email,\n",
    "    joined: date(user.joined),\n",
    "    age: user.age\n",
    "})\n",
    "\"\"\", {'users': user_data})\n",
    "\n",
    "user_count = run_query(\"MATCH (u:User) RETURN count(u) as count\")[0]['count']\n",
    "print(f\"   ‚úÖ Imported {user_count} users\")\n",
    "\n",
    "# Load and import movies with genre relationships\n",
    "print(\"\\n4Ô∏è‚É£ Importing movies from CSV...\")\n",
    "movies_df = pd.read_csv(f'{data_path}/movies.csv')\n",
    "\n",
    "# Prepare movie data\n",
    "movie_data = []\n",
    "for _, movie in movies_df.iterrows():\n",
    "    movie_data.append({\n",
    "        'id': movie['id'],\n",
    "        'title': movie['title'],\n",
    "        'released': movie['released'],\n",
    "        'runtime': int(movie['runtime']),\n",
    "        'budget': int(movie['budget']),\n",
    "        'revenue': int(movie['revenue']),\n",
    "        'plot': movie['plot'],\n",
    "        'genres': movie['genres'].split('|')  # Convert back to list\n",
    "    })\n",
    "\n",
    "# Import movies and create genre relationships in one query\n",
    "run_query(\"\"\"\n",
    "UNWIND $movies as movie\n",
    "CREATE (m:Movie {\n",
    "    id: movie.id,\n",
    "    title: movie.title,\n",
    "    released: date(movie.released),\n",
    "    runtime: movie.runtime,\n",
    "    budget: movie.budget,\n",
    "    revenue: movie.revenue,\n",
    "    plot: movie.plot\n",
    "})\n",
    "WITH m, movie\n",
    "UNWIND movie.genres as genreName\n",
    "MATCH (g:Genre {name: genreName})\n",
    "CREATE (m)-[:IN_GENRE]->(g)\n",
    "\"\"\", {'movies': movie_data})\n",
    "\n",
    "movie_count = run_query(\"MATCH (m:Movie) RETURN count(m) as count\")[0]['count']\n",
    "genre_rel_count = run_query(\"MATCH ()-[r:IN_GENRE]->() RETURN count(r) as count\")[0]['count']\n",
    "print(f\"   ‚úÖ Imported {movie_count} movies\")\n",
    "print(f\"   ‚úÖ Created {genre_rel_count} genre relationships\")\n",
    "\n",
    "print(\"\\nüéâ LOAD CSV import complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits of UNWIND for Batch Operations\n",
    "\n",
    "Notice we used `UNWIND` instead of individual CREATE statements. This is much more efficient:\n",
    "\n",
    "**Instead of**: 50 separate queries\n",
    "```cypher\n",
    "CREATE (p:Person {name: 'John'});\n",
    "CREATE (p:Person {name: 'Jane'});\n",
    "...\n",
    "```\n",
    "\n",
    "**We use**: 1 batch query\n",
    "```cypher\n",
    "UNWIND $people as person\n",
    "CREATE (p:Person {name: person.name})\n",
    "```\n",
    "\n",
    "This reduces network overhead and transaction costs significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add some sample relationships to complete our LOAD CSV demo\n",
    "print(\"üé¨ Adding sample relationships to complete the graph...\\n\")\n",
    "\n",
    "# Create some ACTED_IN relationships\n",
    "sample_relationships = []\n",
    "movies = run_query(\"MATCH (m:Movie) RETURN m.id as id LIMIT 10\")\n",
    "people = run_query(\"MATCH (p:Person) RETURN p.id as id LIMIT 15\")\n",
    "\n",
    "for movie in movies:\n",
    "    # Each movie gets 3-4 actors\n",
    "    selected_actors = random.sample(people, 3)\n",
    "    for actor in selected_actors:\n",
    "        sample_relationships.append({\n",
    "            'person_id': actor['id'],\n",
    "            'movie_id': movie['id'],\n",
    "            'role': fake.first_name() if random.random() > 0.5 else None\n",
    "        })\n",
    "\n",
    "# Batch create relationships\n",
    "run_query(\"\"\"\n",
    "UNWIND $relationships as rel\n",
    "MATCH (p:Person {id: rel.person_id}),\n",
    "      (m:Movie {id: rel.movie_id})\n",
    "CREATE (p)-[:ACTED_IN {role: rel.role}]->(m)\n",
    "\"\"\", {'relationships': sample_relationships})\n",
    "\n",
    "# Create some user ratings\n",
    "users = run_query(\"MATCH (u:User) RETURN u.id as id LIMIT 5\")\n",
    "rating_relationships = []\n",
    "\n",
    "for user in users:\n",
    "    selected_movies = random.sample(movies, 5)\n",
    "    for movie in selected_movies:\n",
    "        rating_relationships.append({\n",
    "            'user_id': user['id'],\n",
    "            'movie_id': movie['id'],\n",
    "            'rating': random.randint(1, 5),\n",
    "            'timestamp': fake.date_time_between(start_date='-1y', end_date='now').isoformat()\n",
    "        })\n",
    "\n",
    "run_query(\"\"\"\n",
    "UNWIND $ratings as rating\n",
    "MATCH (u:User {id: rating.user_id}),\n",
    "      (m:Movie {id: rating.movie_id})\n",
    "CREATE (u)-[:RATED {\n",
    "    rating: rating.rating,\n",
    "    timestamp: datetime(rating.timestamp)\n",
    "}]->(m)\n",
    "\"\"\", {'ratings': rating_relationships})\n",
    "\n",
    "acted_count = run_query(\"MATCH ()-[r:ACTED_IN]->() RETURN count(r) as count\")[0]['count']\n",
    "rating_count = run_query(\"MATCH ()-[r:RATED]->() RETURN count(r) as count\")[0]['count']\n",
    "\n",
    "print(f\"‚úÖ Created {acted_count} ACTED_IN relationships\")\n",
    "print(f\"‚úÖ Created {rating_count} RATED relationships\")\n",
    "print(\"\\nüéâ LOAD CSV import demonstration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Import Performance Tips\n",
    "\n",
    "When working with larger datasets, these tips will save you time and resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate performance optimization techniques\n",
    "print(\"‚ö° Performance optimization techniques for data import:\\n\")\n",
    "\n",
    "print(\"1Ô∏è‚É£ Use PERIODIC COMMIT for large datasets:\")\n",
    "print(\"\"\"\n",
    "// For files with millions of rows\n",
    "USING PERIODIC COMMIT 1000\n",
    "LOAD CSV WITH HEADERS FROM 'file:///large_dataset.csv' AS row\n",
    "CREATE (n:Node {property: row.column})\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ Create constraints BEFORE importing:\")\n",
    "print(\"\"\"\n",
    "// Create constraints first for data integrity and performance\n",
    "CREATE CONSTRAINT person_id FOR (p:Person) REQUIRE p.id IS UNIQUE;\n",
    "// Then import data\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ Use MERGE carefully (it's slower than CREATE):\")\n",
    "print(\"\"\"\n",
    "// MERGE is safe but slower\n",
    "MERGE (p:Person {id: row.person_id})\n",
    "\n",
    "// CREATE is faster but requires clean data\n",
    "CREATE (p:Person {id: row.person_id})\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ Import order matters:\")\n",
    "print(\"\"\"\n",
    "1. Create constraints\n",
    "2. Import nodes (in dependency order)\n",
    "3. Import relationships\n",
    "4. Create additional indexes\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£ Use UNWIND for batch operations:\")\n",
    "print(\"\"\"\n",
    "// Batch multiple operations in one query\n",
    "UNWIND $batch as item\n",
    "CREATE (n:Node {property: item.value})\n",
    "\"\"\")\n",
    "\n",
    "# Let's measure the current performance of our graph\n",
    "print(\"\\nüìä Current graph performance metrics:\")\n",
    "\n",
    "# Simple query performance test\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "result = run_query(\"\"\"\n",
    "MATCH (p:Person)-[:ACTED_IN]->(m:Movie)-[:IN_GENRE]->(g:Genre)\n",
    "RETURN g.name as genre, count(*) as movie_count\n",
    "ORDER BY movie_count DESC\n",
    "LIMIT 5\n",
    "\"\"\")\n",
    "query_time = time.time() - start_time\n",
    "\n",
    "print(f\"   Query execution time: {query_time:.3f} seconds\")\n",
    "print(f\"   Results returned: {len(result)} rows\")\n",
    "\n",
    "print(\"\\nTop genres by number of movies:\")\n",
    "for row in result:\n",
    "    print(f\"   {row['genre']}: {row['movie_count']} movies\")\n",
    "\n",
    "print(\"\\n‚úÖ Performance optimization tips covered!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Knowledge Check #4\n",
    "\n",
    "**Question**: When would you use MERGE vs CREATE when importing data?\n",
    "\n",
    "**Think about it, then check below:**\n",
    "\n",
    "<details>\n",
    "<summary>Click to see the answer</summary>\n",
    "\n",
    "**Use CREATE when:**\n",
    "- You're sure the data doesn't exist (initial load)\n",
    "- You have unique constraints to prevent duplicates\n",
    "- Performance is critical (CREATE is faster)\n",
    "- Your data is clean and validated\n",
    "\n",
    "**Use MERGE when:**\n",
    "- Data might already exist (updates/incremental loads)\n",
    "- You want upsert behavior (create if missing, match if exists)\n",
    "- You're importing from multiple sources that might overlap\n",
    "- Data integrity is more important than speed\n",
    "\n",
    "**Best practice**: Use CREATE for initial loads with constraints, then MERGE for ongoing updates.\n",
    "\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì Module 2 Summary\n",
    "\n",
    "## What You've Accomplished\n",
    "\n",
    "Congratulations! You've completed Module 2 and learned:\n",
    "\n",
    "### ‚úÖ **Data Modeling Mastery**\n",
    "- **Domain analysis** - Converting business requirements to graph models\n",
    "- **Node and relationship design** - Choosing effective graph structures\n",
    "- **Property modeling** - Balancing normalization and performance\n",
    "- **Model validation** - Testing with business queries\n",
    "\n",
    "### ‚úÖ **Import Techniques**\n",
    "- **CREATE statements** - Direct import for learning and small datasets\n",
    "- **LOAD CSV** - Production-ready import for medium datasets\n",
    "- **UNWIND batching** - Efficient bulk operations\n",
    "- **Performance optimization** - Best practices for large-scale imports\n",
    "\n",
    "### ‚úÖ **Data Quality**\n",
    "- **Constraints and indexes** - Ensuring data integrity and performance\n",
    "- **Import validation** - Verifying successful data loads\n",
    "- **Business query testing** - Confirming model effectiveness\n",
    "\n",
    "### ‚úÖ **Real-World Application**\n",
    "- Built a complete movie recommendation system\n",
    "- Handled complex relationships and properties\n",
    "- Implemented collaborative filtering queries\n",
    "- Demonstrated graph advantages over relational approaches\n",
    "\n",
    "## üöÄ What's Next?\n",
    "\n",
    "In **Module 3: Unstructured Data**, you'll learn:\n",
    "- Processing text documents and extracting entities\n",
    "- Building knowledge graphs from unstructured content\n",
    "- Integrating NLP pipelines with Neo4j\n",
    "- Creating embeddings and semantic search\n",
    "\n",
    "## üéØ Final Knowledge Check\n",
    "\n",
    "Before moving on, make sure you can:\n",
    "\n",
    "1. **Design** a graph model from business requirements\n",
    "2. **Choose** appropriate import strategies for different data sizes\n",
    "3. **Create** constraints and indexes for data quality\n",
    "4. **Write** efficient batch import queries\n",
    "5. **Validate** your model with business queries\n",
    "\n",
    "## üí™ Practice Challenge\n",
    "\n",
    "**Try this on your own**: Model an e-commerce system with:\n",
    "- Products, Categories, Customers, Orders\n",
    "- Reviews, Recommendations, Inventory\n",
    "- Import data from CSV files\n",
    "- Answer questions like \"What do customers who bought X also buy?\"\n",
    "\n",
    "You now have all the tools you need for effective data modeling and import!\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations on completing Module 2! You're ready to tackle unstructured data and knowledge graphs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clean up and close connection\n",
    "# Uncomment these lines if you want to clean up\n",
    "# run_query(\"MATCH (n) DETACH DELETE n\")\n",
    "# driver.close()\n",
    "\n",
    "print(\"üéä Module 2 Complete! Excellent work on data modeling and import!\")\n",
    "print(\"üöÄ Ready for Module 3: Unstructured Data\")\n",
    "print(\"\\nüìä Final graph stats:\")\n",
    "\n",
    "final_stats = run_query(\"\"\"\n",
    "MATCH (n)\n",
    "OPTIONAL MATCH ()-[r]-()\n",
    "RETURN count(DISTINCT n) as nodes, count(DISTINCT r) as relationships\n",
    "\"\"\")\n",
    "\n",
    "print(f\"   Nodes: {final_stats[0]['nodes']:,}\")\n",
    "print(f\"   Relationships: {final_stats[0]['relationships']:,}\")\n",
    "print(\"\\nüé¨ You've built a complete movie recommendation graph! üåü\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}