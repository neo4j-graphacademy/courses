= Introduction
:type: lesson
:order: 1
:repository-raw: /Users/adam/graphacademy/llm-chatbot-typescript
// :repository-include: {repository-raw}/main
:repository-include: {repository-raw}

To get you started, we have link:https://github.com/neo4j-graphacademy/llm-chatbot-typescript[created a simple Chatbot interface^].
When you first get the project up and running, it will simply repeat your messages back to you.

But as you progress through the course, you will build the functionality to turn the Chatbot into an _intelligent_ movie recommendation assistant.
It will use the data held in a Neo4j database to improve the responses generated by an LLM.

First, let's take a look at the technology choices we have chosen.


== An introduction to Next.js

We have chosen to implement the chatbot using link:https://nextjs.org/[Next.js^].
You may be familiar with Next.js as a leading framework that extends the latest React features to enable developers to build full-stack applications.

The repository was originally link:https://github.com/vercel/next.js/tree/canary/packages/create-next-app[created with `create-next-app`^] and we have added link:https://tailwindcss.com/docs/guides/nextjs[TailwindCSS^] for presentation.

The front-end UI code creates a chatbot that uses link:https://github.com/neo4j-graphacademy/llm-chatbot-typescript/blob/main/src/hooks/chat.ts[a React hook^] to send an HTTP POST that triggers an agent module.

The route handler subsequently calls the `call()` function in the `src/modules/agent/index.ts` folder.
This function accepts the user `input`, plus a `sessionId` assigned by the framework to identify the user and is responsible for generating a response to the user.

The `call()` function is written to mimic a call to an LLM, using the `setTimeout()` function to wait for a second before returning the same input back to the user.

.Placeholder Agent
[source,typescript]
----
include::{repository-include}/src/modules/agent/index.ts[tag=call]
----

// TODO: Add screenshot


== LLM Integration with Langchain

As you progress through the course, you will replace the `call()` function above with an agent capable of deciphering which tool to use and generating a response with the help of an LLM.

If you have link:/courses/llm-fundamentals/[completed the Neo4j & LLM Fundamentals course^], you will be familiar with Langchain and the concept of agents.
link:https://langchain.com[LangChain^] is an open-source framework designed to accelerate the development of LLM applications.
We have chosen Langchain because it provides a flexible base to test LLMs, and out-of-the-box chains for performing complex tasks.

Although we have chosen a specific framework, the course focuses on the LLM integration details which should be transferrable to your framework of choice.


Although the link:/courses/llm-fundamentals/[Neo4j & LLM Fundamentals course^] covers the Python library and the code samples may differ, the overall concepts used in the TypeScript library are identical.


== LLMs from OpenAI

We have included instructions to integrate the Chatbot with link:https://openai.com[OpenAI's] Large Language Models.

OpenAI has gained prominence through its Generative Pretrained Transformer (GPT) series.
GPT models are trained on vast datasets to generate text that mimics human writing.
The release of GPT-3, and subsequently GPT-4, showcased improvements in language understanding and generation, increasing their application in various industries.
The practical utility of these models in tasks like writing assistance, programming, and language translation has led to widespread adoption and attention.

You are by no means restricted to OpenAI, however.
The hands-on challenges in this course are LLM-agnostic and you are free to use one of the 60+ supported LLMs.

[TIP]
.Open-Source Alternatives
====
If you are looking for an open-source alternative, we recommend that you link:https://github.com/docker/genai-stack/[take a look at the GenAI Stack^].
The GenAI Stack consists of link:https://langchain.com[LangChain^] applications connecting to LLMs served by link:https://https://ollama.ai/[Ollama^], run within link:https://docker.com[Docker^] containers and backed by a Neo4j database.
====


== Complete the course Local or Online

In the next lesson, you will set up your project.
You can either clone or download the repository and complete the exercises locally, or you can use the **Open in Gitpod** buttons to complete the challenges using an Online IDE.


== Ready for launch?

Click the button below to mark this lesson as read.
We will then advance to the next lesson where we will get the project up and running.

read::Lesson Read[]


[.summary]
== Summary

In this lesson, we introduced you to the objectives of the course.

In the next lesson, you will set your environment variables and get the project up and running.
