= Question Rephrasing
:type: challenge
:prompt-filename: rephrase-question.txt
:lab-filename: rephrase-question.chain.ts
:lab-file: modules/agent/chains/{lab-filename}
:lab: {repository-blob}/main/src/{lab-file}
:lab-solution: src/solutions/{lab-file}
:test-filename: rephrase-question.chain.test.ts
:test-file: src/modules/agent/chains/{test-filename}
:order: 5

In this challenge, you must modify the `initGenerateAnswerChain()` function in link:{repository-blob}/main/{lab-file}[`{lab-file}`^] to add a chain that rephrases an input into a standalone question.

The chain will accept the following input:

.Chain Input
[source,typescript]
----
include::{repository-raw}/main/{lab-solution}[tag=interface]
----


The output of the chain will be a `string`.



To convert the message history from an array of objects to a string in the following format: +
[source]
Human: {input}
AI: {output}

You will need to update the `initRephraseChain` method to:

1. Pass the history and input to a `PromptTemplate` containing the prompt in link:{repository-blob}/main/prompts/{prompt-filename}[`prompts/{prompt-filename}`^].
2. Pass the formatted prompt to the LLM
3. Parse the output to a string

Open `{lab-filename}`

== Create a Prompt Template

Use the `PromptTemplate.fromTemplate()` static method to create a new prompt template containing the following prompt.

[source]
.Rephrase Question Prompt
----
include::{repository-raw}/main/prompts/{prompt-filename}[]
----

Your code should resemble the following:


.Prompt Template
[source,typescript,indent=0]
----
include::{repository-raw}/main/{lab-solution}[tag=prompt]
----


== Runnable Sequence

Next, use the `RunnableSequence.from()` static method to create a new chain that takes the `RephraseQuestionInput` and outputs a `string`.

The `RunnableSequence` will need to:

1. Convert message history to a string
2. Use the input and formatted history to format the prompt
3. Pass the formatted prompt to the LLM
4. Coerce the output into a string

Use the `return` keyword to return the sequence from the function.

.Full Sequence
[source,typescript]
----
include::{repository-raw}/main/{lab-solution}[tag=sequence,indent=0]
----

[NOTE]
.Convert Conversation History to a string
====
The `RunnablePassthrough.assign()` static method is another method for modifying individual keys in a chain.

Here, the `messages` input is an array of `(:Response)` nodes from the database.  Prompt templates expect placeholders to be a string, so you must convert the array into a string.

In the following code, the `.map()` method uses the `input` and `output` properties on each response to a format the LLM will understand before the `.join()` method joins them into a single string.

.Reformatting Messages
[source,typescript]
----
include::{repository-raw}/main/{lab-solution}[tag=assign,indent=0]
----
====

== Using the Chain

Later in the course, you will update the application to use the chain.
You could initialize and run the chain with the following code:

[source,typescript, role=nocopy]
----
include::{repository-raw}/main/{lab-solution}[tag=usage]
----

include::../../../../includes/test.adoc[leveloffset=+2]

== It works!

Once you have received a rephrased question from the LLM, click the button below to mark the challenge as completed.

read::It works![]


[.summary]
== Summary

In this lesson, you built a chain that will take this history to rephrase the user's input into a standalone question.

In the next module, you will build a chain that uses a retriever to query a vector store for documents that are similar to an input.
