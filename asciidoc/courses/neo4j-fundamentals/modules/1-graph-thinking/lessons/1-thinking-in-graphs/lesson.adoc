= Thinking in Graphs
:type: video
:order: 1

Have you ever struggled with a complex database schema full of foreign keys and many-to-many relationships that result in unwieldy, poorly performing database queries?

Or do you simply find it difficult to express what you are looking for in your database queries?

Do you deal with hierarchical data or trees, where the answer may lie at an unknown or varying depth?

Or do you need to find a path through an ever-changing dataset with complex requirements?

== Thinking in tables

From early on in our careers, we condition ourselves to think of data in terms of rows and columns, whether in a relational database or even the humble CSV file. Tabular data is a tried-and-tested methodology that works well for most use cases. An ecosystem of tooling even exists to help us work efficiently in this way.

You may not run into any performance issues if the data is small enough.

However, as the amount of data grows or the application or use case becomes more complex, you may run into stumbling blocks.

== Making your data fit

// TODO: Too low-level? Remove?

Let’s take a look at an Entity Relationship diagram that describes the data for a movie recommendation website. The tables highlighted in yellow represent the main entities: users, people, and movies. The green tables, however, are required to support the many-to-many relationships; for example, a user may rate many movies, and a movie may be rated by many users.

This is an example of complexity added to the database layer to make the use case fit the technology. It adds complexity to the data model and may lead to performance issues.

== The O(n) problem

When querying across these tables, the joins are computed at read-time, using an underlying index to find the corresponding rows in the target table.  The more data added to the database, the larger these indexes become and the slower the response.

This problem is known as the “Big O” or O(n) notation.

Many relational databases support subqueries or window functions, but these must still be constructed in memory at query time, which can be expensive.

This problem can be partially resolved by database tuning, partitioning, or denormalizing data to improve response times. At this point, you’ll need to become a database expert to comprehend what’s happening.


== NoSQL Databases

Over the years, many No-SQL databases have sprung up to handle different scenarios. For example, document stores offer flexibility, wide-column stores offer scalability for large datasets, key-value stores provide simplicity and high performance, and graph databases enable efficient modeling and querying of complex relationships between entities.

== Thinking in Documents

Let’s take a document store as an example, where you would store in nested key-value pairs within collections.  This approach provides flexibility and speed of data ingestion but will also have drawbacks when working with connected datasets.

A document store can also fall foul of the O(n) problem.  What happens when you would like to query across collections?  You can store references to documents in other collections by their unique IDs, but the database will still need to compute these joins at read time.

You could start duplicating data or adding caching in your application layer to improve performance, but you are substituting one style of complexity with another.

== Thinking in Graphs

Enter graph databases.

A graph database yields much faster results for queries across or through entities.  A graph database is a great fit when:

* You need tounderstand the relationships between entities
* You have a problem that involves self-referencing between the same type of entity
* You need to explore relationships of varying or unknown depth
* You need to calculate a route between two points in a network

In essence, when the connections between data is as important as the data itself.

Graph databases store data in a structure of nodes and relationships.  
Relationships in a graph are treated with the same importance as nodes that connect them.

When you create a relationship between two nodes, the database stores a pointer to the relationship with the start and end nodes.  So when the time comes to read the data, the database will follow pointers to the relationships in memory rather than relying on an underlying index.

Query time remains constant to the size of the relationships expanded regardless of the overall data size.

You can use a graph database alongside your existing database technology or swap in a graph database as your source of truth.

== Querying Graphs

Graph databases also have their own query language.  Cypher is Neo4j’s implementation of GQL, an ISO standard for graph databases.  Cypher allows you to express patterns in data using an ASCII-art-style syntax similar to how you would draw the data model on a whiteboard.  

Cypher is a declarative language, meaning that the database is responsible for finding the most optimal way to retrieve the data you have requested.

In the next lesson, you will explore common use cases that benefit from a graph database.


== Check Your Understanding




.[.summary]
== Summary

In this lesson, you learned what a Neo4j instance is and the differences between Enterprise Edition and Community Edition.

In the next lesson, you will learn how to do something else...
