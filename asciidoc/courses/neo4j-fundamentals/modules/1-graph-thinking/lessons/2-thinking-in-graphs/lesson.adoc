= Thinking in Graphs
:type: video
:order: 2

Have you ever struggled with a complex database schema full of foreign keys and many-to-many relationships that result in unwieldy, poorly performing database queries?

Or do you simply find it difficult to express what you are looking for in your database queries?

Do you deal with hierarchical data or trees, where the answer may lie at an unknown or varying depth?

Or do you need to find a path through an ever-changing dataset with complex requirements?


== Thinking in tables

Storing data in rows and columns is one of the oldest storage mechanism and existed long before the existing of the computer.

When thinking of data it is typically as a table, whether in a relational database or even the humble CSV file. 
Tabular data is a tried-and-tested methodology that works well for most use cases and an ecosystem of tooling exists to help you work efficiently.

You may not run into any performance issues if the data is small enough.

However, as the amount of data grows or the application or use case becomes more complex, you may encounter stumbling blocks.

== Making your data fit

This is an Entity Relationship diagram that describes the data for a movie recommendation website.

image::images/1-entity-relationship-diagram.png[An Entity Relationship Diagram (ERD)]

The tables highlighted in yellow represent the main entities: users, people, and movies. The green tables, however, are required to support the many-to-many relationships; for example, a user may rate many movies, and a movie may be rated by many users.

This is an example of complexity added to the database layer to make the use case fit the technology. Not only does it add complexity to the data model, but it may also lead to performance issues.


== The O(n) problem

When querying across tables in a relational database, the joins are computed at read-time, using an underlying index to find the corresponding rows in the target table.  
The more data added to the database and subsequently the larger these indexes grow, the slower the response times will become.

This problem is known as the “Big O” or O(n) notation.

Many relational databases support views, sub-queries and window functions which can ease the complexity, but these are still constructed in memory at query time, which is an expensive task.

This problem can be partially resolved by database tuning, partitioning, or de-normalizing data to improve response times. 

== NoSQL Databases

Over the years, many No-SQL databases have sprung up to handle different scenarios. 
For example, document stores offer flexibility, wide-column stores offer scalability for large datasets, key-value stores provide simplicity and high performance, and graph databases enable efficient modeling and querying of complex relationships between entities.

== Thinking in Documents

Let’s take a document store as an example, where you store data in nested key-value pairs within collections.  This approach provides flexibility and speed of data ingestion but will also have drawbacks when working with connected datasets.

[source,json]
.An example Movie Document
----
{
  "_id": ObjectId("63da26bc2e002491266b6205"),
  "title": "Toy Story",
  "released": "1996-03-22",
  "directors": ["Tom Lasseter"]
}
----

The document above contains the names of the directors for the movie as an array of strings.
This is an example of data de-normalization for the purpose of performance.

A document store can also fall foul of the _O(n) problem_.  What happens when you would like to query across collections?  You can store references to documents in other collections by their unique IDs, but the database will still need to compute these joins at read time.

You could start duplicating data or adding caching in your application layer to improve performance, but you are substituting one style of complexity with another.

== Thinking in Graphs

A graph database yields much faster results for queries across or through entities.  
A graph database is a great fit when:

* You need to understand the relationships between entities - for example, how two people are connected
* You have a problem that involves self-referencing between the same type of entity - for example, a hierarchy of employees within a company
* You need to explore relationships of varying or unknown depth - for example, the use of parts within a factory
* You need to calculate a route between two points in a network - for example, finding the most efficient route o public transport

Graph databases store data in a structure of nodes and relationships.
Relationships in a graph are treated with the same importance as nodes that connect them.

When you create a relationship between two nodes, the database stores a pointer to the relationship with each node.  So when the time comes to read the data, the database will follow pointers in memory rather than relying on an underlying index.

This means that the query time remains constant to the size of the relationships expanded regardless of the overall size of the data.


== Querying Graphs

Graph databases have their own query language.  
Cypher is Neo4j's implementation of GQL, an ISO standard for graph databases.
Cypher allows you to express patterns in data using an ASCII-art-style syntax similar to how you would draw the data model on a whiteboard.

Cypher is a declarative language, meaning that the database is responsible for finding the most optimal way of executing that query.

read::Mark as read[]


[.summary]
== Summary

In this lesson, you explored why you may choose to use a graph database.

In the next lesson, you will learn explore typical use cases of a graph database.
