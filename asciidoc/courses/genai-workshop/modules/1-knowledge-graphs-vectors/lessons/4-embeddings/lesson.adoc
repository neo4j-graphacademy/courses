= Creating Embeddings
:order: 4
:type: challenge
:sandbox: true
:branch: main
:slides: true

[.slide]
== Find a movie plot

[.transcript-only]
=====
In this task, you will use Cypher and Python to create embeddings.
=====

To find a movie with a plot *you define*, you need to create an embedding for your text before you can query the vector index.

To find a movie about "A mysterious spaceship lands Earth", you need to:

. Create an embedding for the text "A mysterious spaceship lands Earth".
. Pass the embedding to the `db.index.vector.queryNodes` function.

[.slide]
== Generate embedding

You can generate a new embedding in Cypher using the link:https://neo4j.com/docs/cypher-manual/current/genai-integrations/#single-embedding[`genai.vector.encode`^] function:

[source, cypher]
----
WITH genai.vector.encode(
    "Text to create embeddings for", 
    "OpenAI", 
    { token: "sk-..." }) AS embedding
RETURN embedding
----

[IMPORTANT]
Remember to replace `token: "sk-..."` with your OpenAI API key.

[.slide]
== Query the vector index
You can use the embedding to query the vector index to find similar movies.

[source, cypher]
----
WITH genai.vector.encode(
    "A mysterious spaceship lands Earth", 
    "OpenAI", 
    { token: "sk-..." }) AS myMoviePlot
CALL db.index.vector.queryNodes('moviePlots', 6, myMoviePlot)
YIELD node, score
RETURN node.title, node.plot, score
----

Experiment with different movie plots and observe the results.

[.slide]
== Generate embeddings using Python

You can also use LangChain and the OpenAI API to create embeddings using Python.

Open the `1-knowledge-graphs-vectors\create_embeddings.py` file in the code editor.

[.transcript-only]
====
[source, python]
----
include::{repository-raw}/{branch}/1-knowledge-graphs-vectors/create_embeddings.py[]
----
====

Review the code before running it and note that:

- `load_dotenv()` loads the environment variables from the `.env` file.
- `OpenAIEmbeddings()` creates an instance of the OpenAI embedding class using the `text-embedding-ada-002` model.
- `embedding_provider.embed_query()` creates an embedding for the input text.
- The embedding is printed to the console.

Run the code. 
You should see a list of numbers representing the embedding:

[source]
----
[-0.028445715084671974, 0.009996716864407063, 0.0017208183417096734, -0.010130099952220917, ...]
----

[.next]
== Continue

When you are ready, you can move on to the next task.

read::Move on[]

[.summary]
== Summary

You learned how to create embeddings using Cypher and Python.

In the next task, you will learn how to create a vector index on an embedding.