= Creating Embeddings
:order: 4
:type: challenge
:sandbox: true


In this task, you will use Cypher and Python to create embeddings.

== Find a movie plot

In the previous task, you used a vector index to find similar movies.

To find a movie with a plot you define, you need to create an embedding for your text before you can query the vector index.

For example, to find a movie about "A mysterious spaceship lands Earth", you need to:

. Create an embedding for the text "A mysterious spaceship lands Earth".
. Pass the embedding to the `db.index.vector.queryNodes` function.

You can generate a new embedding in Cypher using the link:https://neo4j.com/docs/cypher-manual/current/genai-integrations/#single-embedding[`genai.vector.encode`^] function:

For example, you can use the `OpenAI` provider to generate an embedding passing the API key as `token` in the `configuration` map:

[source, cypher]
----
WITH genai.vector.encode(
    "Text to create embeddings for", 
    "OpenAI", 
    { token: "sk-..." }) AS embedding
RETURN embedding
----

[IMPORTANT]
Remember to replace `sk-...` with your OpenAI API key.

You can use the embedding to query the vector index to find similar movies.

[source, cypher]
----
WITH genai.vector.encode(
    "A mysterious spaceship lands Earth", 
    "OpenAI", 
    { token: "sk-..." }) AS myMoviePlot
CALL db.index.vector.queryNodes('moviePlots', 6, myMoviePlot)
YIELD node, score
RETURN node.title, node.plot, score
----

Experiment with different movie plots and observe the results.

=== OpenAI API

You can also use the OpenAI API to create embeddings using Python.

Open the `1-knowledge-graphs-vectors\create_embeddings.py` file in the code editor.

[source, python]
----
include::{repository-raw}/main/1-knowledge-graphs-vectors/create_embeddings.py[create]

----

Review the code before running it and note that:

- `load_dotenv()` loads the environment variables from the `.env` file.
- `OpenAI()` creates an instance of the OpenAI class.
- `llm.embeddings.create()` creates an embedding for the input text using the `text-embedding-ada-002` model.
- The response containing the embeddings is printed to the console.

Run the code. 
You should see a list of numbers representing the embedding:

[source]
----
[-0.028445715084671974, 0.009996716864407063, 0.0017208183417096734, -0.010130099952220917, ...]
----

== Continue

When you are ready, you can move on to the next task.

read::Move on[]

[.summary]
== Summary

You learned how to create embeddings using Cypher and Python.

In the next task, you will learn how to create a vector index on an embedding.