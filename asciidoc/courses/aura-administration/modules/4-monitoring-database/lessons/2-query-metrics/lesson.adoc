= Query Rate and Latency
:type: lesson
:order: 3


[.discrete]
== Introduction

Understanding query performance at the database level helps you identify slow queries and performance trends.

In this lesson, you will learn how to monitor query rates, failed queries, and query latency percentiles.


== Query Rate Metrics

The Database tab provides query rate metrics at the database level.


=== Queries Per Minute

The number of successful queries executed per minute on the database.

// UI Description: Queries per minute is the number of successful queries executed per minute on this database.

This metric shows:

* Overall database query load
* Usage patterns over time
* Impact of application changes


=== Failed Queries Per Minute

The number of failed queries executed per minute on the database.

// UI Description: Failed queries per minute is the number of falied queries executed per minute on this database.

Failed queries may result from:

* Syntax errors in Cypher
* Constraint violations
* Query timeouts
* Permission issues
* Out-of-memory errors


== Interpreting Query Rates


=== Normal Query Rate Patterns

**Healthy database**:

* Queries per minute: Stable or gradually increasing
* Failed queries: Very low (< 1% of total)
* Consistent with application usage


=== Warning Signs


==== High Failed Query Rate

If failed queries are a significant portion of total queries:

* Application issues or bugs
* Query syntax errors
* Resource constraints causing timeouts
* Permission configuration issues

**Action**: Review query logs to identify failing queries and root causes.


==== Sudden Changes in Query Rate

Unexpected changes in query rate:

**Sudden increase**:

* New feature deployment
* Increased application usage
* Possible retry storms
* DDoS or abuse

**Sudden decrease**:

* Application outage
* Network issues
* Scheduled downtime
* Users unable to connect


==== Growing Failed Queries

Increasing failed query rate over time:

* Growing resource pressure
* Degrading performance
* Application issues spreading
* Query timeouts becoming common

**Action**: Investigate failed queries and address root causes.


== Query Latency Metrics

Query latency metrics show query execution time in milliseconds.


[NOTE]
.Neo4j version requirement
====
Query latency percentiles are available from Neo4j Version 5.
====


=== 50th Percentile (Median)

The query execution time where 50% of queries executed faster than the reported time.

// UI Description: The query execution time in milliseconds where 50% of queries executed faster than the 
// reported time. This also corresponds to the median of the query execution time. Available from Neo4j Version 5.

This represents the typical query performance for your workload.


=== 75th Percentile

The query execution time where 75% of queries executed faster than the reported time.

// UI Description: The query execution time in milliseconds where 75% of queries executed faster than the 
// reported time. Available from Neo4j Version 5.

This shows how most queries perform, excluding the slowest 25%.


=== 99th Percentile

The query execution time where 99% of queries executed faster than the reported time.

// UI Description: The query execution time in milliseconds where 99% of queries executed faster than the 
// reported time. Available from Neo4j Version 5.

This captures the performance of your slowest queries.

[TIP]
.Why 99th percentile matters
====
The 99th percentile is crucial for user experience - even if most queries are fast, slow outliers can frustrate users.
====


== Interpreting Query Latency


=== Understanding Percentiles

**Low 50th percentile (< 100ms)**:

* Typical queries are fast
* Good user experience for most operations


**High 99th percentile (> 1000ms)**:

* Some queries are slow
* Occasional poor user experience
* May indicate queries needing optimization


**Wide spread (50th vs. 99th)**:

* Inconsistent query performance
* Some queries much slower than others
* Consider query optimization


=== Healthy Latency Patterns

**Simple read queries**: 1-50ms

**Complex traversals**: 50-500ms

**Large aggregations**: 500-5000ms

**Batch operations**: Seconds to minutes


These are guidelines - your acceptable latency depends on use case.


=== Warning Signs


==== Increasing Latency Over Time

If latency percentiles are increasing:

* Database growing beyond available resources
* Page cache hit ratio may be declining
* Indexes may be needed or not being used
* Query patterns changing

**Action**: Review page cache metrics and query logs.


==== High 99th Percentile

If 99th percentile is very high (>10x median):

* Some queries are outliers
* Specific queries need optimization
* May cause timeout errors

**Action**: Review query logs to identify slow queries.


==== All Percentiles High

If all percentiles (50th, 75th, 99th) are high:

* Systemic performance issues
* Instance undersized for workload
* General optimization needed

**Action**: Review all metrics (CPU, memory, page cache) and consider scaling.


== Correlating Metrics

Query rate and latency metrics work together:


=== High Rate + Low Latency

* Efficient queries executing frequently
* Well-optimized database
* Healthy state


=== High Rate + High Latency

* Many slow queries executing
* Performance degraded
* Resource pressure likely
* **Action**: Optimization or scaling needed


=== Low Rate + High Latency

* Few queries but they're slow
* Specific queries need optimization
* May not be resource issue
* **Action**: Focus on query optimization


=== Growing Failed Queries + Increasing Latency

* Performance degradation
* Queries timing out
* Resource exhaustion likely
* **Action**: Immediate investigation required


== Using Query Metrics for Optimization


=== Identify Optimization Opportunities

. Monitor 99th percentile latency
. Look for spikes or trends
. Correlate with query logs
. Identify specific slow queries
. Optimize those queries


=== Measure Impact of Changes

Before and after optimization:

. Record latency percentiles
. Make optimization changes
. Monitor percentiles for improvement
. Validate success


=== Set Latency Targets

Define acceptable latency for your application:

* User-facing queries: < 100ms (50th percentile)
* Reports: < 5000ms (99th percentile)
* Batch operations: Custom limits

Alert when targets are exceeded.


[.quiz]
== Check Your Understanding

include::questions/1-query-latency.adoc[leveloffset=+1]


[.summary]
== Summary

You learned how to monitor query rates and latency for your Aura databases.

You learned that failed queries should be very low (<1% of total) and that the 99th percentile latency is crucial for user experience.

Query latency percentiles help you identify slow queries and measure the impact of optimizations.

In the next lesson, you will learn about monitoring transactions and identifying transaction issues.

