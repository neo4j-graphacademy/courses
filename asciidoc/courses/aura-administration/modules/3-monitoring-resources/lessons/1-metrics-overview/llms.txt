# Viewing Metrics

Understanding the Metrics dashboard, metric categories, and navigation for Aura instance monitoring.

[View lesson](mdc:https://graphacademy.neo4j.com/courses/aura-administration/3-monitoring-resources/1-metrics-overview)

## Concepts

* **Metrics Dashboard** - Central interface for monitoring instance health and performance
* **Resources Tab** - CPU, storage, and Out of Memory error metrics
* **Instance Tab** - Heap memory, page cache, connections, and garbage collection metrics
* **Database Tab** - Store size, query rates, transactions, and entity counts
* **Metric Card** - Individual visualization of a specific metric over time
* **Time Range** - Period for which metrics are displayed (adjustable)
* **Tooltip** - Hover information showing specific metric values at a point in time

## Accessing Instance Metrics

### Quick View on Instance Card

**Purpose:**
* Rapid health check without entering full dashboard
* See key metrics at a glance
* Identify if deeper investigation needed

**Metrics Shown:**
* CPU Usage (last 24 hours)
* Storage (last 24 hours)
* Query Rate (last 24 hours)

**Access Method:**
1. Locate instance card in Aura console
2. Expand "Metrics" section at bottom of card
3. Review high-level indicators

**When to Use:**
* Daily operational checks
* Quick health verification
* Identifying which instances need attention
* Before/after deployment verification

### Full Metrics Dashboard

**Purpose:**
* Comprehensive monitoring and analysis
* Deep-dive into specific metrics
* Historical trend analysis
* Troubleshooting investigations

**Access Methods:**
1. **From Instance Card**:
   * Expand Metrics section
   * Click "View all metrics" button

2. **From Navigation Menu**:
   * Expand "Operations" menu
   * Select "Metrics"

**When to Use:**
* Investigating performance issues
* Capacity planning analysis
* Post-incident review
* Regular detailed monitoring

## Metrics Dashboard Organization

### Three-Tab Structure

**Resources Tab:**
* Focus: Infrastructure utilization
* Audience: Capacity planners, administrators
* Decisions: When to scale instances

**Instance Tab:**
* Focus: JVM and runtime performance
* Audience: Performance engineers, administrators
* Decisions: Memory optimization, connection management

**Database Tab:**
* Focus: Data and query operations
* Audience: DBAs, developers
* Decisions: Query optimization, maintenance scheduling

## Resources Tab Metrics

### CPU Usage

**What It Shows:**
* Minimum, maximum, and average CPU percentage
* CPU consumption patterns over time
* Spikes and sustained high usage

**Why It Matters:**
* High CPU indicates workload stress
* Sustained >70% suggests optimization or scaling needed
* Spikes correlate with expensive operations

**Action Thresholds:**
* <60%: Healthy
* 60-80%: Monitor closely
* >80%: Investigate and optimize
* 100% sustained: Scale immediately

### Storage

**What It Shows:**
* Total storage size in bytes
* Percentage of allocated capacity used
* Growth trends over time

**Why It Matters:**
* Approaching capacity requires scaling
* Growth rate predicts future needs
* Sudden jumps indicate large data imports

**Action Thresholds:**
* <70%: Healthy
* 70-80%: Plan scaling
* >80%: Scale soon
* >90%: Urgent - scale now

### Out of Memory Errors

**What It Shows:**
* Count of OOM errors in time period
* When errors occurred
* Frequency of occurrences

**Why It Matters:**
* Any OOM error is critical
* Indicates queries or load exceeding memory
* Requires immediate investigation

**Action Thresholds:**
* 0: Expected (healthy)
* 1-5: Investigate queries immediately
* >5: Emergency - scale and optimize
* Recurring: Systemic issue requiring resolution

## Instance Tab Metrics

### Heap Memory

**What It Shows:**
* Percentage of heap memory in use
* Min, max, average over time period
* Memory pressure patterns

**Why It Matters:**
* Heap stores query execution state
* High heap leads to garbage collection
* Sustained >80% indicates memory pressure

**When to Review:**
* During performance degradation
* Before capacity planning
* After deployment changes
* When investigating OOM errors

### Page Cache

**What It Shows:**
* Hit ratio: Data found in cache vs disk reads
* Usage ratio: Percentage of cache allocated
* Evictions per minute

**Why It Matters:**
* High hit ratio (>98%) means good performance
* Low hit ratio means data too large for memory
* High evictions indicate cache pressure

**When to Review:**
* Query performance degradation
* After data growth
* Capacity planning
* Performance optimization efforts

### Bolt Connections

**What It Shows:**
* Running connections (executing queries)
* Idle connections (in pool, waiting)
* Opened and closed connection rates

**Why It Matters:**
* Connection patterns indicate app health
* Connection leaks show as growing idle count
* High churn suggests pool misconfiguration

**When to Review:**
* Application connectivity issues
* Performance degradation
* Investigating connection limits
* After application deployments

### Garbage Collection

**What It Shows:**
* Young generation GC percentage
* Old generation GC percentage
* Total GC time percentage

**Why It Matters:**
* High GC time indicates memory pressure
* Frequent old gen GC causes query pauses
* Sustained >5% suggests scaling needed

**When to Review:**
* Query latency spikes
* Memory pressure situations
* Performance troubleshooting
* Capacity planning

## Database Tab Metrics

### Store Size

**What It Shows:**
* Allocated space vs used space
* Database growth over time
* Wasted space after deletions

**Why It Matters:**
* Growth rate predicts capacity needs
* Large difference suggests compaction needed
* Tracks data volume trends

**When to Review:**
* Capacity planning
* After large deletions
* Regular growth monitoring
* Before/after compaction

### Query Rate

**What It Shows:**
* Queries per minute
* Failed queries per minute
* Query volume patterns

**Why It Matters:**
* Shows workload patterns
* Sudden changes indicate issues
* Failed queries require investigation

**When to Review:**
* Performance issues
* After deployments
* Capacity planning
* Regular health checks

### Query Latency

**What It Shows:**
* 50th percentile (median)
* 75th percentile
* 99th percentile

**Why It Matters:**
* 99th percentile shows worst-case performance
* Wide spread indicates inconsistent performance
* Trending up suggests degradation

**When to Review:**
* User complaints about slowness
* After query changes
* Performance optimization
* SLA monitoring

### Entities

**What It Shows:**
* Total node count
* Total relationship count
* Growth over time

**Why It Matters:**
* Tracks graph size growth
* Helps understand data volume
* Useful for capacity planning

**When to Review:**
* Understanding data growth
* Capacity planning
* Data model analysis
* Performance correlation

### Active Transactions

**What It Shows:**
* Read transactions currently active
* Write transactions currently active
* Transaction count per minute

**Why It Matters:**
* High counts may indicate long transactions
* Growing count suggests transaction leaks
* Transaction patterns show workload type

**When to Review:**
* Performance issues
* Memory pressure
* Connection issues
* Application debugging

### Transactions

**What It Shows:**
* Total committed since startup
* Commit rate per minute
* Rollback count and rate

**Why It Matters:**
* Shows workload volume
* Rollback rate indicates errors
* Patterns reveal application issues

**When to Review:**
* High rollback rates
* Performance analysis
* Application troubleshooting
* Capacity planning

### Replan Events

**What It Shows:**
* Total query replans
* Replan rate per minute
* When replans occur

**Why It Matters:**
* Frequent replans indicate non-parameterized queries
* Wastes CPU on plan creation
* Should be low for healthy systems

**When to Review:**
* High CPU usage
* After query changes
* Query optimization efforts
* Parameter usage validation

## Using Metric Cards

### Card Controls

**Time Range Selection:**
* Adjustable period for historical analysis
* Common ranges: 1 hour, 24 hours, 7 days, 30 days
* Custom ranges for specific investigations

**Context Menu (...):**
* **More info** - Detailed metric description
* **Reset zoom** - Return to default view
* **Metrics Integration** - API/export information

**Zoom Capability:**
* Click and drag to zoom into time period
* Useful for investigating specific incidents
* Reset zoom to return to full view

### Reading Card Data

**Tooltip Information:**
* Hover over chart for exact values
* Shows timestamp and metric value
* Dotted line appears on other cards at same time

**Multi-Card Correlation:**
* When hovering on one card, all cards show same timestamp
* Correlate metrics across categories
* Identify cause-and-effect relationships

**Trend Analysis:**
* Upward trends: Growing usage or problems
* Downward trends: Improved performance or reduced load
* Spikes: Specific events or operations
* Patterns: Regular cycles (daily, weekly)

## Navigation Workflow

### Daily Health Check Workflow

**1. Quick Card Scan:**
* Check instance cards for obvious issues
* Look for red indicators or warnings
* Note any unusual patterns

**2. Resources Tab Review:**
* Verify CPU within normal range
* Check storage growth trajectory
* Confirm zero OOM errors

**3. Spot Check Other Tabs:**
* Instance tab: Heap and page cache healthy
* Database tab: Query rates normal

**Time Investment:** 2-5 minutes per instance

### Performance Investigation Workflow

**1. Start with Symptoms:**
* What metric shows the problem?
* When did it start?
* Is it ongoing or resolved?

**2. Set Time Range:**
* Cover period before/during/after incident
* Wide enough to see pattern change
* Narrow enough to see details

**3. Cross-Reference Tabs:**
* Resources: CPU, storage, OOM
* Instance: Heap, GC, connections
* Database: Queries, transactions

**4. Identify Correlations:**
* Which metrics changed together?
* What happened first (cause)?
* What followed (effects)?

**5. Drill Deeper:**
* Switch to query logs for details
* Check security logs if relevant
* Review application logs

**Time Investment:** 15-30 minutes depending on complexity

### Capacity Planning Workflow

**1. Gather Historical Data:**
* Set time range to 30 days or longer
* Export or screenshot key metrics
* Document current baselines

**2. Calculate Growth Rates:**
* Storage growth per day/week
* CPU average trending up?
* Query rate increasing?

**3. Project Future Needs:**
* When will thresholds be reached?
* How much headroom remains?
* What scaling options available?

**4. Plan Scaling Timeline:**
* Buffer time for approvals
* Schedule during low-traffic period
* Prepare rollback plan

**Time Investment:** 1-2 hours for comprehensive planning

[Reference: Monitoring Resources Module](mdc:https://graphacademy.neo4j.com/courses/aura-administration/3-monitoring-resources/)

