= Avoiding Hallucination

The problem with LLMs

* Large language models have the tendency to generate incorrect, nonsensical or unreal results.
* they appear to answer questions confidently even if they don't have the facts
* They may provide contradicting or inconsistent responses to similar prompts


They also have other limitations:

* Knowledge cut-off =
* Lack of knowledge of enterprise/domain knowledge


== Helping LLMs do better

This is where databases come in, and knowledge graphs are a great fit.


* Vector embeddings and searches provide similarity but not context
* A vector that represents an article may be similar to a