= Introduction to Neo4j & GenAI
:order: 1

In this course, we will cover everything you need to know to use Neo4j effectively with Generative AI.
You will learn to all about Large Language Models (LLMs), Knowledge Graphs and how they can be used together effectively.

So we start on the same page, let's first cover the basics.

== What is Neo4j?

Neo4j is a graph database management system that allows us to store, manage, and query highly connected data.
Unlike traditional relational databases, which use tables and rows, Neo4j uses a graph-based model with nodes and relationships.
This makes it particularly well-suited for representing and querying complex, interconnected data.


== What are Knowledge Graphs?

Knowledge Graphs are a specific implementation of a Graph Database, where the underlying data is designed to capture and represent knowledge with a rich semantic context.
They not only capture the entities and connections between, but also the meaning behind them.

Knowledge graphs are tailored for semantic search, data retrieval, reasoning, and data amalgamation, frequently powering search engines, AI, and research.
On the other hand, Neo4j's regular graphs serve diverse roles, such as social networking, recommendations, and fraud detection, not always demanding semantic depth.

Knowledge graphs typically lean on ontologies, offering structured concepts within a domain and their interrelations. Conversely, while Neo4j can engage with ontologies and offers schema constraints, its standard graphs may not consistently utilize or demand structured semantic frameworks.

With their semantic foundation, knowledge graphs can readily adapt and evolve as they assimilate new information and face domain shifts. In contrast, Neo4j, with its schema-free design, emphasizes flexibility in data accommodation rather than adjustments based on changing knowledge or semantics.


== Generative AI & Large Language Models

Generative AI refers to a class of algorithms and models that can generate new content, such as images, text, or even music, based on patterns and examples from existing data. These models learn the underlying structure and distribution of the data and can then generate new samples that resemble the original data.

Generative AI has found applications in a wide range of fields, including image synthesis, text generation, chatbots, and recommendation systems. By leveraging the power of machine learning and deep learning techniques, generative AI models can generate highly realistic and creative outputs.

Large Language Models, most commonly referred to as LLMs, are machine learning models trained on vast amounts of text data to understand and generate human-like text. They can answer questions, create content, and assist with various linguistic tasks by leveraging patterns learned from the data.


== Potential Problems

While LLMs provide a lot of potential, they should also be used with caution.

At their core, LLMs are trained to predict the next word(s) in a sequence.
They convert words into tokens, text into complex vector embeddings; arrays of numbers that can be compared and contrasted.
In that sense, the model is unaware of what any one word in a sequence means compared to another, only their distance or similarity.
It is only aware of the similarity.

For this reason, users may find that, under certain conditions, LLMs can produce inaccurate or biased information, may lack context-awareness, and may struggle with tasks requiring structured and relational reasoning.
This is known as **hallucination**.

Knowledge graphs and graph databases can address these issues by providing LLMs with structured, interconnected data, enabling more accurate context-aware responses and improving reasoning over complex relationships.


== Fixing Hallucinations

Knowledge graphs and graph databases can address these issues by providing LLMs with structured, interconnected data, enabling more accurate context-aware responses and improving reasoning over complex relationships.

Providing data to the LLM as part of the instructions passed to the LLM, known as a **prompt**, along with specific instructions, will greatly reduce the LLMs tendency to provide incorrect information.


Throughout this course, we will explore how to leverage the capabilities of Neo4j and Generative AI to build intelligent, context-aware systems.
We will apply the information learned in the course to build a recommendation engine that queries a movie recommendations dataset through a conversational interface built with Langchain.


== Check Your Understanding

include::questions/1-hallucination.adoc[]

include::questions/2-fixing-hallucination.adoc[]


[.summary]
== Lesson Summary

In this lesson, you learned about LLMs, their potential drawbacks and how they can be avoided.

In the next lesson, you will learn how a knowledge graph can be used to help ground the LLM and avoid hallucinations.
