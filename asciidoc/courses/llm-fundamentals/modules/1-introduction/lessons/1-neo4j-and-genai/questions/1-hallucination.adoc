[.question]
= 1. False Negatives

What is the name given to a confident, but incorrect answer provided by an LLM?

* [ ] Day Dream
* [*] Hallucination
* [ ] Illusion
* [ ] Ungrounding


[TIP,role=hint]
.Hint
====
This phenomenon can occur when the LLM is unaware of the concept, either through bad data or a cut-off date in the training data.
====

[TIP,role=solution]
.Solution
====
The answer is **Hallucination**.
====
