= Improving Semantic Search
:optional: true

// https://www.youtube.com/watch?v=bRD09ndyJNs

In this module, you have learned about the benefits and drawbacks of Semantic Search using an underlying vector index.

You received an answer when querying the vector index for a similar movie, but it is difficult to tell whether that is the best movie in the database.

When using vector-backed semantic search, you are placing a lot of emphasis on the underlying model to provide a good similarity.

The context from which the similarity scores are provided is an important factor here.

We trained the embeddings on a generic dataset, and as such, may identify two movies with a main character called Jack who likes fruit as movies with a close similarity.

This is correct in one sense; they are both movies and very similar when compared to a cricket bat or a vanilla yoghurt. 

On the other hand, if you are recommending a movie to pass away a rainy afternoon, a fairy tale for children is very different to a horror film.

== Incorporating Graph Features

Graph features can enrich vector-backed semantic search by providing structural and relational context to data.

By leveraging the connections in graphs, semantic search can draw upon relationships and hierarchies between entities, enhancing the depth and relevance of search results.

While vectors capture semantic nuances, adding graph structures allows for a more holistic understanding of data, considering its inherent meaning and position in a broader knowledge network.

This topic is out of the scope of this module, but for more information, we recommend watching link:https://www.youtube.com/watch?v=bRD09ndyJNs[Going Meta - Ep 21: Vector-based Semantic Search and Graph-based Semantic Search^], in which Dr Jesus Barassa and Alexander Erdl explore the differences between Vector-based Semantic Search and Graph-based Semantic Search.

== Using Feedback

A more straightforward approach may be to use user feedback to gradually re-rank and curate the content returned by a vector index search.

This is the approach we take with the GraphAcademy chatbot.

To celebrate the launch of the Vector Index, we published an article detailing link:https://medium.com/neo4j/building-an-educational-chatbot-for-graphacademy-with-neo4j-f707c4ce311b[how we used vector index to identify Neo4j content] to improve LLM responses.

The article demonstrates how we ingested Neo4j Documentation and GraphAcademy lessons, using embeddings of the content to populate a vector index.

// TODO: Move to CDN?
image::https://miro.medium.com/v2/resize:fit:4800/format:webp/1*BpDS376rEKb6kWBlxNobRQ.png[The GraphAcademy Chatbot Data Model]

When a user asks a question, the server generates an embedding of the user's question and uses the vector index to identify relevant content.

This approach works well in most cases, but now and again, the index fails to return relevant content, in which case the LLM is instructed to respond to the user with an apology.

When this happens or the user provides feedback, this is stored in the database.

This means over time, we get a better picture of which documents do or do not answer specific queries.

When a new user question comes in, we can compare this question to previous questions, and exclude any suggested documents where the response was considered unhelpful.

// I think we should drop this Cypher, the content above describes it conceptually. 

// [source,cypher,rel=noplay]
// .Excluding Content
// ----
// // Find 10 previous questions for similar questions (> 0.9)
// CALL db.index.vector.queryNodes('questions', 1000, $embedding)
// YIELD node AS unhelpful, score
// WHERE score >= 0.9 AND unhelpful:UnhelpfulResponse

// // Find suggested section where the response was marked as unhelpful
// MATCH (unhelpful)-[:SUGGESTED_SECTION]->(section)

// WITH doc, count(*) AS occurrences
// WHERE occurrences > $threshold

// WITH collect(doc) AS exclude

// // Now, check the documents for similarity
// CALL db.index.vector.queryNodes('documents', 20, $embedding)
// YIELD node AS section, score

// // Exclude previously unhelpful documents
// WHERE NOT section IN exclude

// RETURN section.url AS url, section.text AS text
// ORDER BY score DESC LIMIT 10
// ----

// The `$embedding` parameter above contains an embedding of the current question.


== Module Summary

In this module, you have learned how vector search can be implemented in Neo4j.
You have learned how to create a vector index using the `db.index.vector.createNodeIndex()` procedure, set vector properties using the `db.create.setVectorProperty()` procedure and query the vector index using the `db.index.vector.queryNodes()` procedure.

We have also explored the benefits and potential drawbacks of Vector-based Semantic Search.

In the next module, you will get hands-on with Langchain, a framework designed to simplify the creation of applications using large language models.
