= An introduction to Langchain

To build a Neo4j and LLM integration, you will use a framework called Langchain.

== What is Langchain?

LangChain is an open-source framework designed to accelerate the development of applications powered by LLMs.
The framework enables software developers to quickly build applications that communicate with LLMs, offering integrations with external components and data sources.

Developers can build Langchain applications with link:https://python.langchain.com/[Python^] or link:https://js.langchain.com/[JavaScript/TypeScript^].

Langchain supports multiple Large Language Models out of the box and allows you to swap one for another with a single parameter change.
This means you can easily test multiple LLMs for suitability and utilize different models for different use cases.

Langchain also provides out-of-the-box integrations for many LLMs, APIs and databases including link:https://python.langchain.com/docs/integrations/providers/neo4j[Neo4j^], allowing you to test different LLM providers and models with small code changes.


== How does it work?

LangChain applications act as a bridge between users and LLMs, communicating back and forth with the LLM through **Chains** to determine the best way to fulfill the instructions provided in a _prompt_.

The key components of a Langchain application are:

* **Model Interaction (Model I/O)**: Components that manage the interaction with the language model, overseeing tasks like feeding inputs and extracting outputs.

* **Data Connection and Retrieval:** Retrieval components can access, transform, and store data, allowing for efficient data queries and retrieval.

* **Chains:** Chains combine multiple components into a single application.

* **Agents:** Agents orchestrate a sequence of commands directed at LLMs and other tools, enabling them to perform specific tasks or solve designated problems.

* **Memory:** Allow applications to retain context, for example remembering the previous messages in a conversation.


== A Worked Example

// TODO: Diagram
// https://github.com/docker/genai-stack/blob/main/pdf_bot.py

Let's explore a simple example application that answers questions about a PDF document.

The application uses **Retrieval Augmented Generation** to pass similar text to the user's input the LLM.

[source, python]
----
include::https://raw.githubusercontent.com/docker/genai-stack/main/pdf_bot.py
----

The application consists of:

* A connection to an LLM that will provide embeddings and generated responses
* A **document loader** that loads the PDF contents and creates vector embeddings
* A **retriever** that finds similar documents to the user input
* A **prompt template** to instruct the LLM on how to act
* A conversational **chain** that facilitates document retrieval and manages interaction between the user and the LLM

In the next lesson, we'll look at communicating with LLMs.


== Check Your Understanding

include::questions/1-chains.adoc[leveloffset=+1]
include::questions/2-languages.adoc[leveloffset=+1]


[.summary]
== Lesson Summary

In this lesson, you learned about Langchain, an open-source framework for building AI applications.

In the next lesson, you will learn how you can connect to Neo4j in a Langchain application.
