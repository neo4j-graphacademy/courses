= An introduction to Langchain
:order: 1
:type: lesson

This lesson will teach you about Langchain, an open-source framework for building AI applications.

== What is Langchain?

link:https://langchain.com[LangChain^] is designed to accelerate the development of LLM applications.

Langchain enables software developers to build LLM applications quickly, integrating with external components and data sources.

Developers can build Langchain applications with link:https://python.langchain.com/[Python^] or link:https://js.langchain.com/[JavaScript/TypeScript^].

Langchain supports multiple LLMs and allows you to swap one for another with a single parameter change.

Meaning you can easily test multiple LLMs for suitability and utilize different models for different use cases.

Langchain provides out-of-the-box integrations with APIs and databases including link:https://python.langchain.com/docs/integrations/providers/neo4j[Neo4j^].

Langchain's flexibility allows you to test different LLM providers and models with minimal code changes.

== How does it work?

LangChain applications bridge users and LLMs, communicating back and forth with the LLM through **Chains**.

The key components of a Langchain application are:

* **Model Interaction (Model I/O)**: Components that manage the interaction with the language model, overseeing tasks like feeding inputs and extracting outputs.

* **Data Connection and Retrieval:** Retrieval components can access, transform, and store data, allowing for efficient queries and retrieval.

* **Chains:** Chains are reusable components that determine the best way to fulfill an instruction based on a _prompt_.

* **Agents:** Agents orchestrate commands directed at LLMs and other tools, enabling them to perform specific tasks or solve designated problems.

* **Memory:** Allow applications to retain context, for example, remembering the previous messages in a conversation.

// TODO: need a different simpler example, which includes a prompt template
// == A Worked Example

// // TODO: Diagram
// // https://github.com/docker/genai-stack/blob/main/pdf_bot.py

// Let's explore an link:https://github.com/docker/genai-stack/blob/main/pdf_bot.py[example application^] that answers questions about a PDF document.

// The application uses **Retrieval Augmented Generation** to pass similar text to the user's input the LLM.

// [source, python]
// ----
// include::https://raw.githubusercontent.com/docker/genai-stack/main/pdf_bot.py
// ----

// Review the code and note that the application contains:

// . A connection to an LLM that will provide embeddings and generated responses.
// +
// [source, python]
// ----
// embeddings, dimension = load_embedding_model(
//     embedding_model_name, config={"ollama_base_url": ollama_base_url}, logger=logger
// )

// llm = load_llm(llm_name, logger=logger, config={"ollama_base_url": ollama_base_url})
// ----
// . A **document loader** that loads the PDF contents and creates vector embeddings
// +
// [source, python]
// ----
// pdf_reader = PdfReader(pdf)

// text = ""
// for page in pdf_reader.pages:
//     text += page.extract_text()

// # langchain_textspliter
// text_splitter = RecursiveCharacterTextSplitter(
//     chunk_size=1000, chunk_overlap=200, length_function=len
//         )
// ----
// . A **retriever** that finds similar documents to the user input.
// +
// [source, python]
// ----
// vectorstore = Neo4jVector.from_texts(
//     chunks,
//     url=url,
//     username=username,
//     password=password,
//     embedding=embeddings,
//     index_name="pdf_bot",
//     node_label="PdfBotChunk",
//     pre_delete_collection=True,  # Delete existing PDF data
// )
// ----
// . A **prompt template** to instruct the LLM on how to act.
// +
// [source, python]
// ----
// //TODO - highlight prompt template
// ----
// . A conversational **chain** that facilitates document retrieval and manages interaction between the user and the LLM
// [source, python]
// ----
// qa = RetrievalQA.from_chain_type(
//     llm=llm, chain_type="stuff", retriever=vectorstore.as_retriever()
// )

// qa.run(query, callbacks=[stream_handler])
// ----

In the next lesson, you will set up your development environment and use Langchain to query an LLM.

== Check Your Understanding

include::questions/1-languages.adoc[leveloffset=+1]


[.summary]
== Lesson Summary

In this lesson, you learned about Langchain, an open-source framework for building AI applications.

In the next lesson, you will learn how to set up your development environment and use Langchain to query an LLM.
