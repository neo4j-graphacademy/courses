= Initialising the LLM

// https://python.langchain.com/docs/modules/model_io/models/llms/

To get started with Langchain, you will first need to install the dependencies.

[source,sh]
pip install langchain

== Choosing your LLM

* Langchain supports multiple LLM providers (OpenAI, Cohere, Hugging Face)
* The quality and cost varies
* LLMs are trained for different purposes, so it is worth experimenting with models and prompts until you receive consistent, high quality responses

* In this project, we will use OpenAI
* You can obtain an API Key from platform.openai.com


* Here is how you install the OpenAI SDK


.Install OpenAI SDK
[source,sh]

To create an instance of the OpenAI LLM, import the `OpenAI` class from `langchain.llms`

.Initialize OpenAI
[source,python]
----
from langchain.llms import OpenAI

llm = OpenAI(openai_api_key="...")
----

You can use the LLM instantation to define the `module` to use, and the `temperature`.

When selecting a model, it is worth considering the quality of the output and the cost per token.

As we discussed in the first module, all prompts are accompanied by a `temperature`.
The temperature is a value between `0.0` and `1.0` which affects the randomness, or creativeness of the response.

The following code block creates an interface to communicate with OpenAIs GPT-4 model with a temperature of `0.0`.
In general, this should produce a good response, as grounded in fact as possible.


[source,python]
llm = OpenAI(
    openai_api_key="...",
    model="gpt-4"
    temperature=0.0
)


== Issuing instructions

* The LLM object is callable
* the simplest way to issue an instruction to the LLM is to call `llm` with a string to get a completion.

.Invoke a response
[source,python]
----
response = llm("What is Neo4j?")
----


    Neo4j is an open-source graph database management system. It is used to store and query data with relationships between data elements. This data is stored in the form of a graph, which consists of nodes (data elements) and relationships (connections between nodes). Neo4j is used to build applications that require highly connected data, such as recommendation engines, fraud detection, and master data management.


[TIP]
.LCEL
====
LLMs implement the link:https://python.langchain.com/docs/expression_language/interface[Runnable interface^], the basic building block of the _LangChain Expression Language (LCEL)_. This means they support `invoke`, `stream` and `batch` for synchronous calls and `ainvoke`, `astream` and `abatch` for asynchronous calls.

You can link:https://python.langchain.com/docs/expression_language/interface[learn more in the Interface documentation^].
====

== Executing a Prompt

* You can use the prompt operator to pass a prompt to the LLM

* Prompt Templates allow you to create reusable prompts.
* The Prompt treats anything wrapped in braces as a variable
* The input variables will be validated when the prompt is formatted, and a  `KeyError` will be raised if any variables are missing from the input
* Call the `.format()` method with named parameters for each input.

[source,python]
----
from langchain.prompts import PromptTemplate

template = PromptTemplate.from_template("""
You are a cockney fruit and vegetable seller.
Your role is to assist your customer with their fruit and vegetable needs.
Respond using cockney rhyming slang.

Tell me about the following fruit: {fruit}
""")

template.format(fruit="apple")
----

    'You are a cockney fruit and vegetable seller.
    Your role is to assist your customer with their fruit and vegetable needs
    Respond using cockney rhyming slang.\n\nTell me about the following fruit: apple'


[source,python]
----
llm(template.format(fruit="apple"))
----

    'Apples and pears, guv'nor! Got some nice 'andsome ones in, they'd look lovely on yer mantelpiece'



[TIP]
.Creating PromptTemplates
You can create a prompt from a string by calling the `PromptTemplate.from_template()` static method or load a prompt from a file using the `PromptTemplate.from_file()` static method.




== Check Your Understanding


* Complete the code to instantiate the prompt?
* What are prompts?

[.summary]
== Lesson Summary

In this lesson, you learned how to perform basic communication with an LLM with text and prompt templates.

In the next lesson, you will learn all about Langchain **Chains**.
