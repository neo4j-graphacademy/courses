= Adding the Neo4j Vector Retriever
:order: 9
:type: challenge
:optional: true

In this *optional* challenge, add the movie plots vector retriever to the movie trailer agent you created previously.

To complete the code you will need to update the movie trailer agent to:

. Create the `Neo4jVector` from the `moviePlots` vector index.
. Create the `RetrievalQA` chain using the `Neo4jVector` as the retriever.
. Update the `tools` to use the `RetrievalQA` chain.

[%collapsible]
.Here is the code for the movie trailer agent
====
[source, python]
----
from langchain.prompts import PromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from langchain.chains.conversation.memory import ConversationBufferMemory
from langchain.agents import AgentType, initialize_agent
from langchain.tools import Tool, YouTubeSearchTool

llm = ChatOpenAI(
    openai_api_key="sk-..."
)

youtube = YouTubeSearchTool()

memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

prompt = PromptTemplate(
    template="""
    You are a movie expert. You find movies from a genre or plot. 

    ChatHistory:{chat_history} 
    Question:{input}
    """, 
    input_variables=["chat_history", "input"]
    )

chat_chain = LLMChain(llm=llm, prompt=prompt, memory=memory, verbose=True)

tools = [
    Tool.from_function(
        name="ChatOpenAI",
        description="For when you need to chat about movies. The question will be a string. Return a string.",
        func=chat_chain.run,
        return_direct=True
    ),
    Tool.from_function(
        name="YouTubeSearchTool",
        description="For when you need a link to a movie trailer. The question will be a string. Return a link to a YouTube video.",
        func=youtube.run,
        return_direct=True
    )
]

agent = initialize_agent(
    tools, llm, memory=memory,
    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
)

while True:
    q = input(">")
    print(agent.run(q))
----
====

[%collapsible]
.Here is the code for the movie plots vector retriever
====
[source, python]
----
from langchain.chains import RetrievalQA
from langchain.chat_models.openai import ChatOpenAI
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores.neo4j_vector import Neo4jVector

OPENAI_API_KEY = "sk-..."

chat_llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY)

embedding_provider = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

movie_plot_vector = Neo4jVector.from_existing_index(
    embedding_provider,
    url="bolt://localhost:7687",
    username="neo4j",
    password="pleaseletmein",
    index_name="moviePlots",
    embedding_node_property="embedding", 
    text_node_property="plot",
)

retrievalQA = RetrievalQA.from_llm(
    llm=chat_llm, 
    retriever=movie_plot_vector.as_retriever(), 
    verbose=True, 
    return_source_documents=True
)

r = retrievalQA("A mission to the moon goes wrong")
print(r)
----
====

[TIP]
.Running a RetrievalQA chain from a tool
====
Tools expect a single `query` input and a single string output. 

The `RetrievalQA` chain expects inputs to be passed as positional or keyword arguments.

As a result the agent's tool executor cannot call the `RetrievalQA` chain directly e.g. using `func=retrievalQA.run`.

You could wrap the `RetrievalQA` chain in a function that takes a single string input and returns a single string output.

[source,python]
----
def run_retriever(query):
    results = retrievalQA({"query":query})
    return str(results)

    Tool.from_function(
        ...
        func=run_retriever,
        ...
    )
----
====

[%collapsible]
.Click to reveal the solution
====
There is no right or wrong way to complete this challenge. Here is one potential solution.

[source, python]
----
from langchain.prompts import PromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain, RetrievalQA
from langchain.chains.conversation.memory import ConversationBufferMemory
from langchain.agents import AgentType, initialize_agent
from langchain.tools import Tool, YouTubeSearchTool
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores.neo4j_vector import Neo4jVector

OPENAI_API_KEY = "sk-..."

llm = ChatOpenAI(
    openai_api_key=OPENAI_API_KEY
)

youtube = YouTubeSearchTool()

memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

prompt = PromptTemplate(
    template="""
    You are a movie expert. You find movies from a genre or plot. 

    ChatHistory:{chat_history} 
    Question:{input}
    """, 
    input_variables=["chat_history", "input"]
    )

chat_chain = LLMChain(llm=llm, prompt=prompt, memory=memory, verbose=True)

embedding_provider = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

movie_plot_vector = Neo4jVector.from_existing_index(
    embedding_provider,
    url="bolt://localhost:7687",
    username="neo4j",
    password="pleaseletmein",
    index_name="moviePlots",
    embedding_node_property="embedding", 
    text_node_property="plot",
)

retrievalQA = RetrievalQA.from_llm(
    llm=llm, 
    retriever=movie_plot_vector.as_retriever(), 
    verbose=True, 
    return_source_documents=True
)

def run_retriever(query):
    results = retrievalQA({"query":query})
    return str(results)

tools = [
    Tool.from_function(
        name="ChatOpenAI",
        description="For when you need to chat about movies, genres or plots. The question will be a string. Return a string.",
        func=chat_chain.run,
        return_direct=True
    ),
    Tool.from_function(
        name="YouTubeSearchTool",
        description="For when you need a link to a movie trailer. The question will be a string. Return a link to a YouTube video.",
        func=youtube.run,
        return_direct=True
    ),
    Tool.from_function(
        name="PlotRetrieval",
        description="For when you need to compare a plot to a movie. The question will be a string. Return a string.",
        func=run_retriever,
        return_direct=True
    )
]

agent = initialize_agent(
    tools, llm, memory=memory,
    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
    verbose=True, 
    handle_parsing_errors=True,
)

while True:
    q = input(">")
    print(agent.run(q))
----
====

== Summary

In this optional challenge, you added the movie plots vector retriever to the movie trailer agent you created previously. 

In the next module, you will learn how to use an LLM to generate Cypher and improve the responses of an LLM.

read::Continue[]

[.summary]
== Summary

In this optional challenge, you added the movie plots vector retriever to the movie trailer agent you created previously. 

In the next module, you will learn how to use an LLM to generate Cypher and improve the responses of an LLM.
