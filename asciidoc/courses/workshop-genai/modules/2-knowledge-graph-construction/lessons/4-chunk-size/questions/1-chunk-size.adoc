[.question]
= What is the primary trade-off when increasing the chunk size in the SimpleKGPipeline?

* [ ] Larger chunks process faster but use more memory
* [x] Larger chunks provide more context for entity extraction but result in less granular data
* [ ] Larger chunks create more entities but fewer relationships
* [ ] Larger chunks improve accuracy but require more computational power

[TIP,role=hint]
.Hint
====
Consider what happens to the level of detail and context when you make text chunks bigger or smaller.
====

[TIP,role=solution]
.Solution
====
**Larger chunks provide more context for entity extraction but result in less granular data**. The larger the chunk size, the more context the LLM has when extracting entities and relationships, but it may also lead to less granular data. This is the key trade-off - more context versus granularity of the extracted information.
====
