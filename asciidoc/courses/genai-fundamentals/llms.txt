# Neo4j & GenerativeAI Fundamentals

Learn how Neo4j and GraphRAG can support your Generative AI projects

[Learn more about this course](mdc:https:/graphacademy.neo4j.com/courses/genai-fundamentals)

## Concepts

* **Generative AI (GenAI)** - Artificial intelligence systems designed to create new content that resembles human-made data, including text, images, audio, or code. These models learn patterns from large datasets to generate new output.

* **Large Language Models (LLMs)** - A type of generative AI model designed to understand and generate human-like text. Trained on vast amounts of text data, they perform tasks like answering questions, summarizing data, and analyzing text through probabilistic continuation of instructions.

* **Prompt** - Instructions provided to an LLM that specify requirements and provide clear guidance on how to respond. Precision in task description, combined with examples or context, ensures the model understands intent and produces relevant outputs.

* **Hallucination** - A phenomenon where LLMs generate misleading or baseless content. LLMs are fine-tuned to be helpful even if it means occasionally generating inaccurate information, as they lack genuine understanding or ethical judgment.

* **Temperature** - A parameter controlling the amount of randomness in LLM text generation. Higher temperature values produce more random and potentially false statements, while lower values ensure more consistent and precise responses.

* **Context** - Relevant information, data, or details provided in prompts to help LLMs generate more accurate and relevant responses. Context minimizes hallucinations by anchoring responses to supplied facts and compensates for lack of access to real-time or proprietary data.

* **Grounding** - The process of providing context to an LLM to improve response accuracy and reduce hallucinations. This involves retrieving relevant information from external sources and including it in the prompt.

* **Retrieval-Augmented Generation (RAG)** - An approach that enhances LLM responses by providing relevant, up-to-date information retrieved from external sources. Combines understanding user queries, retrieving relevant information, and generating responses using the retrieved context.

* **Retriever** - A component that takes unstructured input (like a question or prompt) and searches for structured data that can provide context or answers. Retrievers can use full-text search, vector search, or text-to-Cypher methods.

* **Semantic Search** - A search approach that understands search phrases' intent and contextual meaning rather than focusing on individual keywords. Uses vector representations to gauge context and return tailored results based on perceived intent.

* **Vector** - A list of numbers representing data points in multi-dimensional space. Vectors can represent text, images, audio, or other data types, with dimensionality determining the granularity of meaning captured.

* **Embedding** - Numerical translations of data objects (images, text, audio) represented as vectors. Each dimension can represent a particular semantic aspect, and when combined, they convey the overall meaning of the word or phrase.

* **Vector Index** - A database index structure optimized for finding approximate nearest neighbors in high-dimensional vector space. Enables efficient similarity search by comparing vector distances or angles.

* **GraphRAG (Graph Retrieval Augmented Generation)** - An approach that uses graph database strengths to provide relevant context to LLMs. Enhances vector RAG by leveraging relationships and structure within a graph, enabling richer context, improved accuracy, explainability, flexible queries, and enhanced reasoning.

* **Knowledge Graph** - An organized representation of real-world entities and their relationships. Provides structured, interconnected data that enhances context, reasoning, and accuracy in generated responses for Generative AI applications.

* **Organizing Principles** - Rules or categories around data that provide structure to knowledge graphs. These principles can range from simple data descriptions to complex vocabularies, stored as nodes alongside actual data to enable complex queries and analytics.

* **Text-to-Cypher** - An approach in GraphRAG that allows users to express information needs in natural language, which is automatically translated into Cypher queries. Leverages LLMs to interpret user intent and generate precise graph queries.

## Understanding Generative AI and LLM Limitations

### When to Use
* Beginning GenAI projects requiring understanding of model capabilities
* Evaluating whether LLMs are appropriate for your use case
* Planning applications that need accurate, factual responses
* Assessing risks and limitations before implementation

### Step-by-Step Process
1. **Understand Model Nature** - Recognize that LLMs are probabilistic text prediction machines, not intelligent systems with understanding
2. **Assess Training Data Limitations** - Consider that training data may be outdated, of questionable quality, or lack proprietary information
3. **Identify Hallucination Risks** - Understand that models may generate plausible but false content, especially with higher temperature settings
4. **Evaluate Transparency Needs** - Recognize that LLMs cannot provide sources or explain reasoning, making them "black boxes"
5. **Plan Context Strategy** - Determine how to provide relevant context to improve accuracy and reduce hallucinations

### Best Practices
**DO:**
* Use lower temperature settings (closer to 0) for consistent, precise responses requiring factual accuracy
* Provide explicit context in prompts when accuracy is critical
* Include relevant data, statistics, or documents directly in prompts for proprietary or recent information
* Specify clear requirements and instructions in prompts with examples when needed
* Test responses and validate accuracy, especially for critical applications

**DON'T:**
* Assume LLMs understand or comprehend content they generate
* Rely solely on training data for current or proprietary information
* Use high temperature settings for applications requiring factual accuracy
* Trust responses without validation, especially for legal, medical, or financial contexts
* Skip providing context when dealing with domain-specific or time-sensitive information

### Validation Checklist
- [ ] Model limitations understood and documented
- [ ] Temperature settings appropriate for use case
- [ ] Context provision strategy defined
- [ ] Hallucination risks assessed and mitigated
- [ ] Response validation process established
- [ ] Transparency requirements identified

[Reference: Generative AI > Considerations](mdc:https:/graphacademy.neo4j.com/courses/genai-fundamentals/1-generative-ai/2-considerations)

## Providing Context to Improve LLM Responses

### When to Use
* LLM responses need higher accuracy and relevance
* Working with proprietary or domain-specific information
* Requiring up-to-date information beyond training data cutoff
* Minimizing hallucinations in critical applications
* Need to ground responses in specific facts or data

### Step-by-Step Process
1. **Identify Context Requirements** - Determine what information the LLM needs to generate accurate responses
2. **Gather Relevant Data** - Collect documents, reports, statistics, or data points relevant to the query
3. **Structure Context** - Organize context in a clear, accessible format within the prompt
4. **Anchor Responses** - Include specific facts and details that anchor the model's response to reality
5. **Validate Output** - Verify that responses accurately reflect the provided context

### Best Practices
**DO:**
* Include relevant information directly in prompts for accuracy
* Provide context that directly addresses the query's information needs
* Use structured data (tables, lists) when presenting statistics or data points
* Supply recent events or organization-specific information as part of the prompt
* Combine multiple context sources (documents, APIs, databases) for comprehensive grounding

**DON'T:**
* Assume the model has access to proprietary or recent information
* Skip context provision to save prompt space
* Provide irrelevant or conflicting context that confuses the model
* Rely on the model's training data for domain-specific knowledge
* Forget to update context when information changes

### Validation Checklist
- [ ] Context directly addresses query requirements
- [ ] All proprietary or recent information included
- [ ] Context is clear and well-structured
- [ ] Responses validated against provided context
- [ ] Context sources are reliable and up-to-date

[Reference: Generative AI > Context](mdc:https:/graphacademy.neo4j.com/courses/genai-fundamentals/1-generative-ai/3-context)

## Implementing RAG (Retrieval-Augmented Generation)

### When to Use
* Building applications that need accurate, up-to-date responses
* Working with information not present in LLM training data
* Requiring real-time data integration (APIs, databases, documents)
* Need to ground responses in external knowledge sources
* Building chatbots or Q&A systems with domain-specific knowledge

### Step-by-Step Process
1. **Understand User Query** - Interpret the user's input or question to determine what information is needed
2. **Select Data Sources** - Choose appropriate sources (documents, APIs, knowledge graphs) based on query type
3. **Configure Retriever** - Set up retriever using appropriate method (full-text, vector, or text-to-Cypher)
4. **Retrieve Relevant Information** - Search external data sources to find relevant information based on the query
5. **Generate Response** - Insert retrieved information into prompt and use LLM to generate accurate, context-aware response

### Best Practices
**DO:**
* Use RAG for applications requiring real-time or proprietary data
* Combine multiple retrieval methods (vector + graph traversal) for richer context
* Validate retrieved information before passing to LLM
* Structure retrieved data clearly in prompts
* Monitor retrieval quality and adjust strategies based on response accuracy

**DON'T:**
* Rely solely on LLM training data for current information
* Use single retrieval method when multiple approaches would improve results
* Skip validation of retrieved information quality
* Overload prompts with irrelevant retrieved context
* Ignore retrieval performance and relevance scoring

### Validation Checklist
- [ ] Retriever configured for appropriate data sources
- [ ] Retrieval method matches query type and requirements
- [ ] Retrieved information validated for relevance and accuracy
- [ ] Context properly structured in prompts
- [ ] Response quality monitored and improved iteratively

[Reference: RAG > What is RAG](mdc:https:/graphacademy.neo4j.com/courses/genai-fundamentals/2-rag/1-what-is-rag)

## Implementing Vector-Based Semantic Search

### When to Use
* Need to find contextually similar content based on meaning
* Working with unstructured text data (documents, articles, descriptions)
* Requiring fuzzy or vague query matching
* Handling broad or open-ended questions
* Need to understand semantic relationships between concepts

### Step-by-Step Process
1. **Choose Embedding Model** - Select appropriate embedding model matching your data type and requirements
2. **Create Embeddings** - Generate vector representations for source data using the embedding model
3. **Build Vector Index** - Create vector index in database (e.g., Neo4j) for efficient similarity search
4. **Encode Query** - Convert user query into vector embedding using same model
5. **Perform Similarity Search** - Compare query vector to indexed vectors using distance or angle metrics
6. **Score and Rank Results** - Return results ordered by similarity score (0.0 to 1.0)

### Best Practices
**DO:**
* Use same embedding model for both indexing and query encoding
* Create embeddings for entire sentences or paragraphs, not individual words
* Consider dimensionality trade-offs (higher = more nuance, lower = faster/cheaper)
* Use vector search for contextual or meaning-based questions
* Validate similarity scores and review top results for relevance

**DON'T:**
* Mix different embedding models between indexing and querying
* Use vector search for highly specific or exact-match queries
* Rely on vectors for numerical or boolean queries
* Ignore similarity scores when evaluating results
* Use vectors for specialized knowledge without domain-specific training

### Validation Checklist
- [ ] Embedding model consistent across indexing and querying
- [ ] Vector dimensionality appropriate for use case
- [ ] Similarity scores validated against expected results
- [ ] Query type appropriate for vector search (not exact-match)
- [ ] Results reviewed for semantic relevance

[Reference: RAG > Vector Search](mdc:https:/graphacademy.neo4j.com/courses/genai-fundamentals/2-rag/2-vector-search)

## Using Vector Indexes in Neo4j

### When to Use
* Need efficient similarity search on large datasets
* Working with Neo4j graph database
* Requiring approximate nearest neighbor search
* Building RAG systems with Neo4j as data source
* Need to combine vector search with graph traversal

### Step-by-Step Process
1. **Prepare Data** - Ensure nodes have embedding properties containing vector representations
2. **Create Vector Index** - Use `CREATE VECTOR INDEX` to create index on embedding property
3. **Generate Query Embedding** - Use `genai.vector.encode()` function or external API to create query embedding
4. **Query Vector Index** - Use `db.index.vector.queryNodes()` procedure with index name, number of neighbors, and query vector
5. **Process Results** - Extract nodes and similarity scores from query results
6. **Combine with Graph Traversal** - Optionally traverse graph from matched nodes to find related entities

### Best Practices
**DO:**
* Use vector indexes for semantic similarity search on large datasets
* Combine vector search with graph traversal for richer context
* Specify appropriate number of nearest neighbors based on use case
* Review similarity scores to understand result relevance
* Use same embedding model for both indexing and querying

**DON'T:**
* Use vector indexes for exact-match or highly specific queries
* Ignore similarity scores when evaluating results
* Create indexes without considering query patterns
* Mix embedding models between indexing and querying
* Rely solely on vector similarity without graph relationships

### Validation Checklist
- [ ] Vector index created on appropriate property
- [ ] Query embedding generated with compatible model
- [ ] Number of neighbors appropriate for use case
- [ ] Similarity scores reviewed and validated
- [ ] Graph traversal integrated when needed

[Reference: RAG > Vector Index](mdc:https:/graphacademy.neo4j.com/courses/genai-fundamentals/2-rag/3-vector-index)

## Implementing GraphRAG Techniques

### When to Use
* Need richer context through relationship traversal
* Requiring explainable retrieval results
* Working with complex queries combining multiple concepts
* Need to leverage graph structure for enhanced reasoning
* Building applications requiring relationship-aware responses

### Step-by-Step Process
1. **Perform Initial Retrieval** - Use vector search or full-text search to find initial relevant nodes
2. **Traverse Graph Relationships** - From matched nodes, traverse relationships to find related entities
3. **Collect Context** - Gather related nodes, relationships, and properties into context
4. **Score and Filter** - Optionally score or filter results based on relevance or additional criteria
5. **Structure Context** - Organize retrieved graph data clearly for LLM consumption
6. **Generate Response** - Pass structured graph context to LLM for enhanced response generation

### Best Practices
**DO:**
* Combine vector search with graph traversal for comprehensive context
* Use graph relationships to find related entities (actors, genres, categories)
* Leverage graph structure for explainable retrieval paths
* Score results using graph properties (ratings, weights, metadata)
* Return context alongside responses for transparency

**DON'T:**
* Use graph traversal alone without initial retrieval step
* Traverse too many relationship hops (causes noise)
* Ignore relationship types when traversing
* Skip scoring or ranking when multiple paths exist
* Forget to validate graph traversal results

### Validation Checklist
- [ ] Initial retrieval method appropriate (vector/full-text)
- [ ] Graph traversal strategy defined and tested
- [ ] Relationship types relevant to query
- [ ] Context properly structured for LLM
- [ ] Results validated for relevance and accuracy

[Reference: RAG > GraphRAG](mdc:https:/graphacademy.neo4j.com/courses/genai-fundamentals/2-rag/4-graphrag)

## Constructing Knowledge Graphs

### When to Use
* Need structured representation of entities and relationships
* Working with diverse data sources requiring integration
* Building GenAI applications requiring domain-specific knowledge
* Need to organize and query complex, interconnected information
* Requiring flexible schema that can evolve with data

### Step-by-Step Process

#### From Unstructured Data:
1. **Gather Data** - Collect data from multiple sources in different formats (text documents, PDFs, web pages)
2. **Chunk Data** - Break down data into manageable parts that LLMs can process effectively
3. **Vectorize Data** - Create vector embeddings for querying and searching (if needed)
4. **Extract Entities and Relationships** - Pass chunks to LLM with context/constraints to extract nodes and relationships
5. **Generate Graph** - Use LLM output to create nodes and relationships in graph database
6. **Validate Structure** - Review extracted entities and relationships for accuracy

#### From Structured Data:
1. **Identify Sources** - Determine data sources (relational databases, CSV files, APIs, other graphs)
2. **Analyze Data** - Understand entities (rows/tables), attributes (columns), and relationships (foreign keys)
3. **Define Graph Schema** - Map entities to nodes, relationships to edges, define organizing principles
4. **Transform and Import** - Convert structured data into graph format and import into database
5. **Validate Import** - Verify data integrity and relationship accuracy

### Best Practices
**DO:**
* Define clear organizing principles before construction
* Use LLMs to automate extraction from unstructured data
* Map existing structured data directly to graph schema
* Validate extracted entities and relationships
* Plan for schema evolution as data grows
* Integrate diverse sources for holistic view

**DON'T:**
* Skip schema definition when working with structured data
* Extract entities without considering relationships
* Ignore data quality issues before import
* Create overly complex schemas initially
* Forget to validate extraction accuracy
* Lock schema too early in development

### Validation Checklist
- [ ] Data sources identified and accessible
- [ ] Graph schema defined (nodes, relationships, properties)
- [ ] Organizing principles established
- [ ] Extraction/transformation process validated
- [ ] Data quality verified
- [ ] Schema supports intended queries

[Reference: Knowledge Graphs > Constructing Knowledge Graphs](mdc:https:/graphacademy.neo4j.com/courses/genai-fundamentals/3-knowledge-graphs/2-constructing-knowledge-graphs)

## Building GraphRAG Pipelines with Neo4j GraphRAG

### When to Use
* Building Python applications integrating Neo4j with GenAI
* Need first-party, maintained package for Neo4j GenAI integration
* Requiring retrievers, GraphRAG pipelines, or knowledge graph construction
* Building production applications needing long-term support
* Need fast access to new Neo4j GenAI features

### Step-by-Step Process
1. **Set Up Environment** - Install `neo4j-graphrag` package and configure Neo4j connection
2. **Configure Embedder** - Create embedder using appropriate model (must match existing embeddings)
3. **Create Retriever** - Build retriever (VectorRetriever, VectorCypherRetriever, or TextToCypherRetriever)
4. **Configure LLM** - Set up LLM with appropriate model and temperature settings
5. **Build GraphRAG Pipeline** - Combine retriever and LLM into GraphRAG pipeline
6. **Test and Iterate** - Submit queries, review results, and refine configuration

### Best Practices
**DO:**
* Use same embedding model as existing vector indexes
* Set temperature to 0 for deterministic Cypher generation
* Return context alongside responses for transparency
* Configure retriever with appropriate properties to return
* Use VectorCypherRetriever to combine vector search with graph traversal
* Provide example queries for TextToCypherRetriever accuracy

**DON'T:**
* Mix embedding models between indexing and retrieval
* Use high temperature for Cypher query generation
* Skip context return for debugging and transparency
* Create retrievers without specifying return properties
* Execute LLM-generated Cypher without validation in production
* Ignore retriever configuration options

### Validation Checklist
- [ ] Environment configured with required dependencies
- [ ] Embedder matches existing vector index model
- [ ] Retriever type appropriate for use case
- [ ] LLM configured with appropriate temperature
- [ ] GraphRAG pipeline tested with sample queries
- [ ] Context returned for transparency

[Reference: Integrating Neo4j > Neo4j GraphRAG](mdc:https:/graphacademy.neo4j.com/courses/genai-fundamentals/4-integrating-neo4j/1-neo4j-graphrag)

## Creating Vector Retrievers

### When to Use
* Need semantic search on vector-indexed data
* Building RAG systems with vector-based retrieval
* Working with unstructured text requiring similarity search
* Need to find contextually relevant documents or content

### Step-by-Step Process
1. **Connect to Neo4j** - Establish database connection using Neo4j Python driver
2. **Create Embedder** - Configure embedder with model matching vector index (e.g., `text-embedding-ada-002`)
3. **Create Vector Retriever** - Initialize VectorRetriever with vector index name and embedder
4. **Specify Return Properties** - Configure which node properties to return from matched nodes
5. **Perform Search** - Use retriever's `search()` method with query and number of results
6. **Process Results** - Extract and use returned items with similarity scores

### Best Practices
**DO:**
* Ensure embedder model matches vector index embedding model
* Specify relevant properties to return from matched nodes
* Review similarity scores to understand result relevance
* Test with various queries to validate retrieval quality
* Use retriever as component in larger RAG pipeline

**DON'T:**
* Use different embedding models for retriever and index
* Return unnecessary properties (increases response size)
* Ignore similarity scores when evaluating results
* Skip testing with diverse query types
* Use retriever in isolation without LLM integration

### Validation Checklist
- [ ] Embedder model matches vector index
- [ ] Return properties specified appropriately
- [ ] Search results validated for relevance
- [ ] Similarity scores reviewed
- [ ] Retriever integrated into RAG pipeline

[Reference: Integrating Neo4j > Vector Retriever](mdc:https:/graphacademy.neo4j.com/courses/genai-fundamentals/4-integrating-neo4j/2-vector-retriever)

## Building RAG Pipelines

### When to Use
* Need to provide context to LLMs from retrieved data
* Building Q&A systems or chatbots
* Requiring accurate responses grounded in external data
* Need to combine retrieval with generation

### Step-by-Step Process
1. **Create Retriever** - Build appropriate retriever (vector, graph-enhanced, or text-to-Cypher)
2. **Configure LLM** - Set up LLM with appropriate model and temperature settings
3. **Build GraphRAG Pipeline** - Combine retriever and LLM using GraphRAG class
4. **Submit Query** - Use `search()` method with user query
5. **Configure Retrieval** - Optionally specify retriever_config (number of results, etc.)
6. **Return Context** - Set `return_context=True` to see retrieved data used for response
7. **Iterate and Refine** - Adjust temperature, retriever config, and query based on results

### Best Practices
**DO:**
* Use lower temperature (0-0.3) for consistent, factual responses
* Return context for transparency and debugging
* Configure retriever to return appropriate number of results
* Test with various query types to validate pipeline
* Monitor response quality and adjust configuration iteratively
* Combine multiple retrieval methods for richer context

**DON'T:**
* Use high temperature for applications requiring accuracy
* Skip returning context (reduces transparency)
* Retrieve too many or too few results
* Assume responses are always accurate without validation
* Ignore retriever configuration options
* Use single retrieval method when combination would improve results

### Validation Checklist
- [ ] Retriever configured appropriately
- [ ] LLM temperature set for use case
- [ ] Context return enabled for transparency
- [ ] Pipeline tested with diverse queries
- [ ] Response quality validated
- [ ] Configuration optimized based on results

[Reference: Integrating Neo4j > RAG](mdc:https:/graphacademy.neo4j.com/courses/genai-fundamentals/4-integrating-neo4j/3-rag)

## Creating Graph-Enhanced Vector Retrievers

### When to Use
* Need to leverage graph relationships for richer context
* Requiring related entities beyond initial vector matches
* Building applications needing relationship-aware responses
* Want to combine semantic similarity with graph structure

### Step-by-Step Process
1. **Design Retrieval Query** - Create Cypher query that receives vector search results and traverses graph
2. **Specify Relationships** - Define which relationships to traverse (genres, actors, categories, etc.)
3. **Add Scoring/Filtering** - Include graph-based scoring (ratings, weights) or filtering criteria
4. **Create VectorCypherRetriever** - Initialize with vector index name, retrieval query, and embedder
5. **Test Retrieval** - Validate that graph traversal returns relevant related entities
6. **Integrate with Pipeline** - Use retriever in GraphRAG pipeline for enhanced context

### Best Practices
**DO:**
* Traverse relevant relationship types based on query intent
* Use graph properties (ratings, metadata) for scoring and ranking
* Limit traversal depth to avoid noise
* Return structured data (lists, aggregations) for LLM consumption
* Validate that graph traversal adds value beyond vector search
* Use graph relationships to provide explainable retrieval paths

**DON'T:**
* Traverse too many relationship hops (causes irrelevant results)
* Ignore relationship direction when traversing
* Skip scoring when multiple paths exist
* Return unstructured graph data
* Use graph traversal without initial vector search
* Forget to validate traversal results

### Validation Checklist
- [ ] Retrieval query designed for use case
- [ ] Relationship types relevant to queries
- [ ] Graph traversal adds value to results
- [ ] Results properly structured for LLM
- [ ] Scoring/filtering configured appropriately
- [ ] Retriever integrated and tested

[Reference: Integrating Neo4j > Vector Graph](mdc:https:/graphacademy.neo4j.com/courses/genai-fundamentals/4-integrating-neo4j/4-vector-graph)

## Implementing Text-to-Cypher Retrieval

### When to Use
* Need to answer specific questions about nodes, relationships, or properties
* Requiring complex queries (aggregations, filters, traversals)
* Building natural language interfaces to graph databases
* Need precise data retrieval based on exact criteria
* Want to leverage graph schema for structured queries

### Step-by-Step Process
1. **Configure LLM for Cypher Generation** - Use LLM with temperature set to 0 for deterministic query generation
2. **Define Graph Schema** - Provide schema (or let retriever read automatically) describing nodes, relationships, and properties
3. **Create Example Queries** - Provide example user queries with corresponding Cypher queries to guide generation
4. **Create TextToCypherRetriever** - Initialize with LLM, schema, and examples
5. **Submit Natural Language Query** - Pass user query to retriever
6. **Validate Generated Cypher** - Review generated query before execution (especially in production)
7. **Execute and Process Results** - Run Cypher query and format results for LLM context

### Best Practices
**DO:**
* Set temperature to 0 for deterministic Cypher generation
* Provide clear, relevant example queries
* Limit schema scope to relevant nodes/relationships for accuracy
* Validate generated Cypher queries before execution
* Handle exceptions for invalid or unsafe queries
* Use schema constraints to guide query generation
* Test with diverse query types to improve accuracy

**DON'T:**
* Use high temperature for Cypher generation (causes inconsistency)
* Skip example queries (reduces accuracy)
* Provide overly broad schema (reduces precision)
* Execute LLM-generated queries without validation in production
* Ignore security implications of generated queries
* Trust generated queries blindly without testing

### Validation Checklist
- [ ] LLM temperature set to 0
- [ ] Graph schema provided (or auto-read)
- [ ] Example queries relevant and clear
- [ ] Generated Cypher validated before execution
- [ ] Exception handling for invalid queries
- [ ] Security measures in place for production

[Reference: Integrating Neo4j > Text to Cypher](mdc:https:/graphacademy.neo4j.com/courses/genai-fundamentals/4-integrating-neo4j/5-text-to-cypher)

## Choosing Retrieval Methods

### Decision Framework

**Use Vector Search When:**
* Queries are contextual or meaning-based
* Need fuzzy or vague query matching
* Handling broad or open-ended questions
* Working with unstructured text requiring semantic similarity
* Need to find conceptually similar content

**Use Full-Text Search When:**
* Queries require exact keyword or phrase matching
* Need to find specific entities by name
* Working with structured text requiring precise matches
* Need to filter results by specific keywords

**Use Graph Traversal When:**
* Need related entities beyond initial matches
* Requiring relationship-aware context
* Want explainable retrieval paths
* Need to leverage graph structure for reasoning
* Building applications requiring relationship understanding

**Use Text-to-Cypher When:**
* Queries are highly specific or fact-based
* Need complex queries (aggregations, filters)
* Requiring precise data retrieval
* Want to leverage graph schema for structured queries
* Need to answer questions about specific properties

**Combine Methods When:**
* Need comprehensive context from multiple sources
* Queries span multiple information types
* Requiring both semantic similarity and precise matching
* Want to leverage both vector similarity and graph relationships

### Best Practices
**DO:**
* Match retrieval method to query type and requirements
* Combine methods for richer context when appropriate
* Validate retrieval quality for each method
* Use appropriate method for data type (structured vs unstructured)
* Test retrieval methods with diverse query types

**DON'T:**
* Use single method when combination would improve results
* Apply vector search to exact-match queries
* Use text-to-Cypher for vague or open-ended questions
* Ignore retrieval method performance characteristics
* Skip validation of retrieval quality

### Validation Checklist
- [ ] Retrieval method matches query type
- [ ] Method appropriate for data structure
- [ ] Combination of methods considered when beneficial
- [ ] Retrieval quality validated
- [ ] Performance characteristics understood

## Selecting GenAI Frameworks

### When to Use
* Building complex GenAI workflows requiring orchestration
* Need LLM usage, prompt management, and output handling
* Requiring embedding model integration and vector database support
* Building agentic workflows or RAG systems
* Need monitoring, observability, or deployment tools

### Popular Framework Options

**LangChain (Python/JS)** - Leading open-source framework with strong Neo4j support for vector stores and knowledge graphs. Best for comprehensive GenAI application development.

**LlamaIndex** - Data framework for connecting LLMs to external data with Neo4j connectors. Best for RAG and knowledge graph use cases.

**Spring AI / Langchain4j** - Java ecosystem frameworks for integrating AI into Java applications. Best for Java-based GenAI applications.

**Haystack** - Framework for building search and Q&A systems with Neo4j integration. Best for search-focused applications.

**Semantic Kernel** - Microsoft orchestration library for AI workflows. Best for Microsoft ecosystem integration.

**DSPy** - Framework for programming and optimizing LLM pipelines. Best for advanced pipeline optimization.

### Best Practices
**DO:**
* Choose framework matching your technology stack
* Evaluate framework's Neo4j integration capabilities
* Consider long-term maintenance and community support
* Assess framework features against your requirements
* Use frameworks to accelerate development, not replace understanding

**DON'T:**
* Choose framework without evaluating Neo4j integration
* Overlook framework maintenance and support status
* Use framework without understanding underlying concepts
* Ignore framework limitations or constraints
* Skip evaluating multiple frameworks before choosing

### Validation Checklist
- [ ] Framework matches technology stack
- [ ] Neo4j integration capabilities verified
- [ ] Framework features meet requirements
- [ ] Community support and maintenance assessed
- [ ] Framework limitations understood

[Reference: Integrating Neo4j > Frameworks](mdc:https:/graphacademy.neo4j.com/courses/genai-fundamentals/4-integrating-neo4j/6-frameworks)
