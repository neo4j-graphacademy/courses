= Connect to an LLM
:order: 1
:type: challenge
:optional: true

* In `src/modules/llm.ts`, create an instance of the `ChatOpenAI` exported from `@langchain/openai`, using the `OPENAI_API_KEY` environment variable set in `.env.local`.
* The test in `src/modules/llm.test.ts` imports this variable and calls the invoke method.  Try experimenting with the prompt.

[%collapsible]
.View Solution
====

.src/modules/llm.ts
[source,typescript]
----
import { ChatOpenAI } from "@langchain/openai";

export const llm = new ChatOpenAI({
  openAIApiKey: process.env.OPENAI_API_KEY,
  modelName: "gpt-4o",
  temperature: 0,
});
----
====

To verify this challenge, run the following test:

.Run Test
[source,sh]
----
npm run test llm
----

If all tests pass, hit the button below to continue.
If anything goes wrong, shout!

read::It passes![]

[.summary]
== Summary

Good job, you're ready for the next challenge.

