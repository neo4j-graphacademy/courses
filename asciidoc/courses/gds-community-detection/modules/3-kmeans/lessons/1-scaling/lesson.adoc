= Feature normalization
:sandbox: true
:type: quiz

[.transcript]
KMeans is an unsupervised learning algorithm designed to cluster a dataset into a specific number of communities (K), which you decide beforehand. It operates in iterations, initially assigning each data point to its nearest centroid, or cluster center, then calculating new centroids based on the mean of all data points within each cluster. This iterative process continues until the centroids stabilize without notable changes or the maximum iteration limit is reached. KMeans measures distance between a data point and a centroid using the Euclidean distance.

It's important to note that Euclidean distance can be swayed by the scale of input features. If your features aren't normalized, the ones with larger values might unfairly dominate the distance calculation, leading to skewed community detection results. That's where feature normalization steps in, ensuring every feature weighs equally in the distance calculation.

== Scaling Node Properties

In the survey dataset, most features range from one to five. However, some features follow different scales, and we've also incorporated one-hot-encoding, which offers just two values: 0 and 1. That's why we need to scale node properties to ensure all features are equally represented by the KMeans algorithm. The Graph Data Science library comes to the rescue with the gds.alpha.scaleProperties procedure for feature normalization.

Our first step involves projecting an in-memory graph, which includes the vector node property we determined earlier.

.Projecting In-Memory Graph
[source,cypher]
CALL gds.graph.project(
  'survey',
  'Person',
  '*',
  {nodeProperties:['vector']}
);

The gds.alpha.scaleProperties procedure offers six normalization methods:

* Min-max scaler
* Max scaler
* Mean scaler
* Log scaler
* Standard Score
* Center

For this case, we're choosing the Min-max scaler for feature normalization. We'll apply the mutate mode because we want to store the results back onto the projected in-memory graph.

.Applying Min-Max Scaler
[source,cypher]
CALL gds.alpha.scaleProperties.mutate(
  'survey',
  {
    nodeProperties: ['vector'],
    scaler: 'MinMax',
    mutateProperty: 'scaledVector'
  }
)

In this segment, we delved into the workings of the KMeans algorithm, an unsupervised learning method designed to cluster data into predetermined communities. We emphasized the importance of feature normalization due to the sensitivity of the Euclidean distance measurement, which KMeans uses.

We then discussed the necessity of scaling node properties in our survey dataset to ensure all features are equally represented during clustering. To achieve this, we utilized the `gds.alpha.scaleProperties` procedure, choosing the Min-max scaler as our normalization method.



== Check your understanding

include::questions/1-euclidean.adoc[leveloffset=+1]

include::questions/2-scaler.adoc[leveloffset=+1]

[.summary]
== Summary

In this lesson, we delved into the KMeans algorithm and the importance of feature normalization in unsupervised learning, specifically how to scale node properties for equal representation using the Graph Data Science library.

In the next lesson, we'll dive into using the KMeans algorithm for community detection tasks, teaching you how to effectively group your data.
