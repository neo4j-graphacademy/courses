= Creating an Agent
:type: challenge
:order: 3
:lab: {repository-link}/

The first step towards an LLM-integrated chatbot is to create an **Agent**.

You may recall in the link:/courses/llm-fundamentals/3-intro-to-langchain/4-agents/[Agents lesson in the Neo4j & LLM Fundamentals course^], that Agents are objects that use an LLM to identify and execute a sequence of actions in response to a user input.

In this challenge, you must:

1. Use the `initialize_agent` function to create a new agent
2. Create a handler function that instructs the agent to handle
3. Call the new handler function from `bot.py`

lab::Open in Online IDE[]


== Initializing an Agent

Langchain provides an `initialize_agent()` function for creating a new Agent.

To create a new agent, create a new `agent.py` file, and copy and paste the code below.


[source,python]
----
from langchain.agents import AgentType, initialize_agent

# Include the LLM from a previous lesson
from llm import llm

include::{repository-raw}/main/solutions/agent.py[tag=agent]
----

Let's take a look at the parameters passed to the function call in more detail.


=== `tools`

The `initialize_agent()` requires a list of tools as the first positional argument.
We will define tools later on, but for now, you can this has been set to an empty list.

[source,python]
.Empty Tools List
----
tools = []
----

=== `llm`

This is set to the instance of `ChatOpenAI` created in link:../1-llm/[Creating an LLM Instance^].

[source,python]
----
from llm import llm
----



=== Conversation Memory

To allow the bot to maintain a list of recent messages, you can pass an instance of `ConversationBufferWindowMemory` to the `initialize_agent()` function.


// TODO: Update to Neo4jConversationalMemory

[source,python]
.Conversational Memory
----
include::{repository-raw}/main/solutions/agent.py[tag=memory]
----


=== Agent Type

The `agent` parameter specifies the type of agent to use.
This defaults to a Zero-Shot ReAct agent (`AgentType.ZERO_SHOT_REACT_DESCRIPTION`), an agent that determines which of the tools to use based purely on the
descriptions provided in the tools array.

We aim to build a conversational chatbot, so the `agent` parameter has been set to `AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION`.
A Conversational agent is designed to be used in conversational settings.
It uses the ReAct framework to decide which tool to use, and uses memory to remember the previous conversation interactions.


[TIP]
.Chosing an Agent Type
====
You can learn more about the different types of Agents available in the Langchain documentation.

link:https://python.langchain.com/docs/modules/agents/agent_types/[Langchain Documentation: Agent Types^]
====

== Verbose Output

When the `verbose` argument is set to `True`, you can view the reasoning the agent has used in the console.

[%collapsible]
.An example output
====
    > Entering new AgentExecutor chain...
    {
        "action": "Cypher QA",
        "action_input": "What are some films starring Leonardo DiCaprio?"
    }

    > Entering new GraphCypherQAChain chain...
    Generated Cypher:
    MATCH (p:Person)-[:ACTED_IN]->(m:Movie)
    WHERE p.name = "Leonardo DiCaprio"
    RETURN m.title AS film_starring_Leonardo_DiCaprio
    Full Context:
    [{'film_starring_Leonardo_DiCaprio': 'Great Gatsby, The'}, {'film_starring_Leonardo_DiCaprio': 'Gangs of New York'}, {'film_starring_Leonardo_DiCaprio': 'Aviator, The'}, {'film_starring_Leonardo_DiCaprio': 'Departed, The'}, {'film_starring_Leonardo_DiCaprio': 'Total Eclipse'}, {'film_starring_Leonardo_DiCaprio': 'Basketball Diaries, The'}, {'film_starring_Leonardo_DiCaprio': 'Titanic'}, {'film_starring_Leonardo_DiCaprio': 'Man in the Iron Mask, The'}, {'film_starring_Leonardo_DiCaprio': "William Shakespeare's Romeo + Juliet"}, {'film_starring_Leonardo_DiCaprio': 'Blood Diamond'}]

    > Finished chain.

    Observation: {'query': 'What are some films starring Leonardo DiCaprio?', 'result': 'Some films starring Leonardo DiCaprio include "Great Gatsby, The", "Gangs of New York", "Aviator, The", "Departed, The", "Total Eclipse", "Basketball Diaries, The", "Titanic", "Man in the Iron Mask, The", "William Shakespeare\'s Romeo + Juliet", and "Blood Diamond".'}
    Thought:{
        "action": "Final Answer",
        "action_input": "Some films starring Leonardo DiCaprio include 'Great Gatsby, The', 'Gangs of New York', 'Aviator, The', 'Departed, The', 'Total Eclipse', 'Basketball Diaries, The', 'Titanic', 'Man in the Iron Mask, The', 'William Shakespeare's Romeo + Juliet', and 'Blood Diamond'."
    }
====


== Add a Handler Function

The `agent` object returned by the `initialize_agent` function is callable and expects a single input, the user's input.
The function returns a `dict` that will contain an `answer` key containing the final response generated by the LLM.

At the bottom of the file, create a new `generate_response()` function to replicate the value.
The role of the function should be to take a single string input, call the `agent` object and return the answer generated by the LLM.


[source,python]
.Conversational Memory
----
include::{repository-raw}/main/solutions/agent.py[tag=generate_response]
----

== Calling the new Handler function

You can now update the bot to call the new `generate_response()` function by modifying the `handle_submit()` function in `bot.py`.

Start by importing the `handle_submit()` from the `agent.py` file.


[source,python]
----
include::{repository-raw}/main/solutions/agent.py[tag=import]
----

Now modify the `handle_submit()` button to instead call the `handle_submit()` method.
You can use the `write_message()` function to display the message on screen.


[source,python]
----
include::{repository-raw}/main/solutions/agent.py[tag=submit]
----


== Receving a Response

You should now have the makings of an intelligent LLM-integrated chatbot.
If you ask a question, you should get a generated response from the LLM appended to the list of messages.

video::images/working-with-llm.mp4[role=cdn,width=610,height=410]

Once you have received a response from the LLM, click the button below to mark the challenge as completed.

read::It works![]


[.summary]
== Summary

In this lesson, you created a Conversation agent that is capable of communicating with an LLM.
However, it is a good idea to specify what kind of questions the LLM can respond to.

In the next lesson, you will define the scope of the agent and restrict the type of responses it provides.
