= Querying with LLMs
:order: 2
:type: lesson
:branch: main
:lab: {repository-raw}/{branch}/llm-knowledge-graph/query_kg.py

Using an LLM to generate cypher can help you query the knowledge graph, particularly when the schema is created from unstructured data.
The LLM uses the knowledge graph schema to dynamically create Cypher queries.

The link:https://graphacademy.neo4j.com/courses/llm-fundamentals/4-cypher-generation/[Using LLMs for Query Generation^] module in the link:https://graphacademy.neo4j.com/courses/llm-fundamentals[Neo4j & LLM Fundamentals^] course covers how to generate Cypher using Python and Langchain.

In this lesson, you will explore options for improving Cypher generation for knowledge graphs.

== Cypher Generation

Open the `llm-knowledge-graph/query_kg.py` file:

[%collapsible]
.View query_kg.py
====
[source,python]
----
include::{repository-raw}/{branch}/llm-knowledge-graph/query_kg.py[tag=**]
----
====


This program uses link:https://api.python.langchain.com/en/latest/chains/langchain.chains.graph_qa.cypher.GraphCypherQAChain.html[GraphCypherQAChain^] and a custom prompt to generate Cypher queries.

Run the program and ask a simple question.

    > How many chunks are in the graph?
    > Entering new GraphCypherQAChain chain...
    Generated Cypher:
    MATCH (c:Chunk)
    RETURN COUNT(c) as numberOfChunks;
    Full Context:
    [{'numberOfChunks': 70}]
    > Finished chain.

Ask more complex questions to see how the LLM generates Cypher queries.

You will probably find that the queries generated do not return the correct results.

You can improve the results by tuning the prompt and configuring the chain.

== Prompt

The name of entities in the knowledge graph are not always in the same case as the question.

You can include an additional instruction and example in the prompt to help the LLM understand generate this Cypher:

[source, python]
----
include::{repository-raw}/{branch}/llm-knowledge-graph/solutions/query_kg_prompt.py[tag=case]
----

You can also provide specific examples related to navigating the graph structure.
For example, how to find documents from the entities extracted.

[source, python]
----
include::{repository-raw}/{branch}/llm-knowledge-graph/solutions/query_kg_prompt.py[tag=documents]
----

Providing specific examples improves the Cypher generated by the LLM.

    > What documents are about the technology LLM?
    > Entering new GraphCypherQAChain chain...
    Generated Cypher:
    MATCH (d:Document)<-[:PART_OF]-(:Chunk)-[:HAS_ENTITY]->(t:Technology)
    WHERE t.id =~ '(?i)LLM'
    RETURN d

    > what is the most reference technology entity by chunk?
    > Entering new GraphCypherQAChain chain...
    Generated Cypher:
    MATCH (c:Chunk)-[:HAS_ENTITY]->(t:Technology)
    RETURN t.id, COUNT(*) AS references
    ORDER BY references DESC
    LIMIT 1

Ask questions of different complexity to see how the LLM generates Cypher queries.
Adapt your prompt to cater for specific scenarios by providing instructions or examples.

== Configuration

The link:https://api.python.langchain.com/en/latest/chains/langchain.chains.graph_qa.cypher.GraphCypherQAChain.html[GraphCypherQAChain^] also provides configuration options to improve the Cypher generated.

=== Exclude types

If there are node labels or relationship types that you wish exclude from your Cypher queries, you can use the `exclude_types` parameter.

For example, if you are storing conversation history alongside your knowledge graph, you could exclude those nodes and relationships.

image::/courses/llm-fundamentals/3-intro-to-langchain/3.7-persist-memory/images/Neo4jChatMessageHistory.svg[The converstion graph structure showing Session, Message node labels and LAST_MESSAGE, NEXT relationship types.]

[source, python]
----
include::{repository-raw}/{branch}/llm-knowledge-graph/solutions/query_kg_exclude.py[tag=exclude_types]
----

=== Enhanced schema

If the properties within your knowledge graph contain a relatively small range of values, you may benefit from using the `enhanced_schema` parameter.

When you set the `enhanced_schema` parameter, the system scans property values and provides examples to the LLM when generating Cypher queries.

This can lead to more accurate Cypher queries, at the cost of more complex prompts, and potentially slower generation times.

[source, python]
----
include::{repository-raw}/{branch}/llm-knowledge-graph/solutions/query_kg_enhanced.py[tag=enhanced_schema]
----

=== LLM Configuration

You can configure the link:https://api.python.langchain.com/en/latest/chains/langchain.chains.graph_qa.cypher.GraphCypherQAChain.html[GraphCypherQAChain^] to use different LLMs for Cypher and question/answer generation.

Using different LLMs can give give improved performance and/or better cost efficiency.
Picking the right LLM for the right task can be a trade-off between speed and accuracy.

For example, using 2 different OpenAI LLM models, `gpt-4` for cypher generation and `gpt-3.5-turbo` for question/answer generation.

[source, python]
----
include::{repository-raw}/{branch}/llm-knowledge-graph/solutions/query_kg_llms.py[tags="llms,cypher_chain"]
----

[TIP]
A temperature of `0` is recommended for Cypher generation.

Experiment by asking questions, adapting the prompt, and configuring the chain to improve the Cypher generated by the LLM.

== Check Your Understanding

include::questions/1-exclude-data.adoc[leveloffset=+1]

[.summary]
== Lesson Summary

In this lesson, you learned how to use the `GraphCypherQAChain` to generate Cypher queries from a knowledge graph schema.

In the next lesson, you will create a retriever to query the knowledge graph using unstructured data.